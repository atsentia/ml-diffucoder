# -*- coding: utf-8 -*-
"""2025-07-13 TinyDiffusion Cleaned up Notebook

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LgUeRGdGre1ppHbE3lRy27F7Akg-ldn9

# 0. PREPARATION AND PACKAGE INSTALLS
"""

!pip install datasets transformers sentencepiece

"""# 1. TRAINING CODE

## 1.1 TinyStories D3PM Text Diffusion Model and Config

```python
test_suite = TestD3PM()
all_passed = test_suite.run_all_tests()
```

Sample output:
```
JAX version: 0.5.2
Available devices: [TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0)]
Running D3PM tests...
==================================================
Testing model forward pass...
✓ Model forward pass test passed
Testing loss computation...
✓ Loss computation test passed (loss=7.2581)
Testing training step...
✓ Training step test passed (loss=7.4035)
Testing sampling...
✓ Sampling test passed
Testing full pipeline...
✓ Full pipeline test passed
==================================================
Tests passed: 5/5

All tests passed! Running simulation...
Simulating D3PM training...
==================================================

Generating samples...
Sample 1: word_12 word_115 word_20 word_918 word_983 word_780 word_512 word_972 word_152 word_249 word_736 wor...
Sample 2: word_367 word_18 word_353 word_59 word_516 word_382 word_672 word_157 word_861 word_203 word_596 wor...
Sample 3: word_967 word_886 word_606 word_301 word_156 word_347 word_191 word_4 word_916 word_485 word_713 wor...

Simulation completed!`

```

## 1.1b Explanation of cell code

This code defines a **Discrete Denoising Diffusion Probabilistic Model (D3PM)** for text, specifically tailored for the TinyStories dataset. It provides a complete, simplified framework for training and testing a discrete diffusion model for text generation.

---

## Key Components

* **`D3PMConfig`**: A dataclass that holds all hyperparameters for the model and training process. This includes settings like vocabulary size, sequence length, model dimensions, number of diffusion steps (`T`), learning rate, and batch size.

* **`MockDataset` & `MockTokenizer`**: These are simple mock implementations for the dataset and tokenizer. They allow the model to be tested and simulated without needing the actual TinyStories dataset or a full SentencePiece tokenizer.

* **`TransformerBlock`**: A standard Transformer block implemented in Flax. It includes a self-attention mechanism and a feed-forward network, complete with residual connections and layer normalization.

* **`D3PMDenoiser`**: This is the core neural network of the model. It's a Transformer-based denoiser that takes token IDs and a timestep `t` as input. It then outputs logits that predict the original, uncorrupted tokens. The architecture includes token, time, and positional embeddings.

* **`D3PMTrainer`**: This class manages the entire training process. It handles the initialization of the model, the AdamW optimizer, and the diffusion schedule (betas).
    * **`q_sample`**: Implements the forward diffusion process, which progressively masks tokens based on the diffusion step `t`.
    * **`loss_fn`**: Calculates the training loss. The loss is the cross-entropy between the model's predicted logits and the original tokens, focusing specifically on the positions that were masked.
    * **`train_step`**: Executes a single training step. It's compiled using JAX's `jit` for high performance.
    * **`eval_step`**: Computes evaluation metrics, such as bits per token (BPT).
    * **`get_data_loader`**: A simple data generator for feeding data to the model.
    * **`train`**: The main loop that iterates through the training process.
    * **`sample`**: Implements the reverse denoising process to generate new text sequences from noise.

* **`TestD3PM`**: A comprehensive test suite designed to verify the correctness of the model's implementation. It includes tests for the forward pass, loss computation, training step, and the sampling procedure.

* **`simulate_training`**: A function to run a short training simulation using the mock data. This demonstrates the end-to-end pipeline and ensures all components work together as expected.

---

## Summary

In essence, this script sets up a complete, albeit simplified, framework for training a discrete diffusion model for text generation. The inclusion of mock data, comprehensive tests, and a simulation function allows for robust verification of the core components before scaling up to real datasets and larger model architectures.
"""

# TinyStories D3PM - Fixed Implementation with Tests and Simulation
# Complete JAX/Flax discrete diffusion model with comprehensive error handling

import jax
import jax.numpy as jnp
import flax.linen as nn
import optax
import numpy as np
import functools
import itertools
import time
from typing import Dict, Any, Optional, Tuple, Iterator
from dataclasses import dataclass
import logging
from pathlib import Path

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class D3PMConfig:
    """Configuration for D3PM model"""
    vocab_size: int = 8000
    seq_length: int = 256
    d_model: int = 256
    n_heads: int = 8
    n_layers: int = 6
    d_ff: int = 1024
    dropout_rate: float = 0.1

    # Diffusion parameters
    T: int = 12
    beta_start: float = 0.0
    beta_end: float = 0.3

    # Training parameters
    batch_size: int = 64
    learning_rate: float = 2e-4
    weight_decay: float = 1e-2
    max_steps: int = 150_000
    log_every: int = 100
    eval_every: int = 1000
    save_every: int = 10_000

class MockDataset:
    """Mock dataset for testing when actual TinyStories isn't available"""

    def __init__(self, vocab_size: int = 8000, seq_length: int = 256):
        self.vocab_size = vocab_size
        self.seq_length = seq_length
        self.mask_id = vocab_size - 1

    def __iter__(self):
        """Generate random sequences for testing"""
        while True:
            # Generate random sequences with some structure
            seq_len = np.random.randint(50, self.seq_length)
            sequence = np.random.randint(4, self.vocab_size - 1, size=seq_len)
            # Pad to fixed length
            padded = np.pad(sequence, (0, self.seq_length - seq_len),
                          constant_values=0)
            yield padded.astype(np.int32)

class MockTokenizer:
    """Mock tokenizer for testing"""

    def __init__(self, vocab_size: int = 8000):
        self.vocab_size = vocab_size
        self.mask_id = vocab_size - 1

    def encode(self, text: str) -> list:
        # Simple mock encoding
        return [hash(word) % (self.vocab_size - 1) + 1 for word in text.split()][:256]

    def decode(self, ids: list) -> str:
        # Simple mock decoding
        return " ".join([f"word_{id}" for id in ids if id not in [0, self.mask_id]])

    def piece_to_id(self, piece: str) -> int:
        if piece == "[MASK]":
            return self.mask_id
        return hash(piece) % (self.vocab_size - 1) + 1

class TransformerBlock(nn.Module):
    """Transformer block with proper residual connections"""
    d_model: int
    n_heads: int
    d_ff: int
    dropout_rate: float = 0.1

    @nn.compact
    def __call__(self, x, deterministic: bool = False):
        # Self-attention with residual
        attn_out = nn.SelfAttention(
            num_heads=self.n_heads,
            dropout_rate=self.dropout_rate,
            deterministic=deterministic
        )(nn.LayerNorm()(x))
        x = x + attn_out

        # Feed-forward with residual
        ff_out = nn.Dense(self.d_ff)(nn.LayerNorm()(x))
        ff_out = nn.gelu(ff_out)
        ff_out = nn.Dense(self.d_model)(ff_out)
        ff_out = nn.Dropout(rate=self.dropout_rate, deterministic=deterministic)(ff_out)
        x = x + ff_out

        return x

class D3PMDenoiser(nn.Module):
    """D3PM Denoiser with proper architecture"""
    config: D3PMConfig

    @nn.compact
    def __call__(self, token_ids, t_idx, deterministic: bool = False):
        config = self.config

        # Input validation
        if token_ids.shape[-1] != config.seq_length:
            raise ValueError(f"Expected sequence length {config.seq_length}, got {token_ids.shape[-1]}")

        # Token embeddings
        x = nn.Embed(
            num_embeddings=config.vocab_size,
            features=config.d_model,
            name="token_embed"
        )(token_ids)

        # Time embeddings
        t_emb = nn.Embed(
            num_embeddings=config.T,
            features=config.d_model,
            name="time_embed"
        )(t_idx)

        # Add time embedding to each position
        x = x + t_emb[:, None, :]

        # Positional embeddings
        pos_emb = nn.Embed(
            num_embeddings=config.seq_length,
            features=config.d_model,
            name="pos_embed"
        )(jnp.arange(config.seq_length))
        x = x + pos_emb[None, :, :]

        # Transformer layers
        for i in range(config.n_layers):
            x = TransformerBlock(
                d_model=config.d_model,
                n_heads=config.n_heads,
                d_ff=config.d_ff,
                dropout_rate=config.dropout_rate
            )(x, deterministic=deterministic)

        # Output projection
        x = nn.LayerNorm()(x)
        logits = nn.Dense(config.vocab_size)(x)

        return logits

class D3PMTrainer:
    """Main trainer class for D3PM"""

    def __init__(self, config: D3PMConfig, use_mock_data: bool = False):
        self.config = config
        self.use_mock_data = use_mock_data

        # Initialize model
        self.model = D3PMDenoiser(config=config)

        # Initialize tokenizer and dataset
        if use_mock_data:
            self.tokenizer = MockTokenizer(config.vocab_size)
            self.dataset = MockDataset(config.vocab_size, config.seq_length)
        else:
            self.tokenizer = self._init_real_tokenizer()
            self.dataset = self._init_real_dataset()

        self.mask_id = config.vocab_size - 1

        # Diffusion schedule
        self.betas = jnp.linspace(config.beta_start, config.beta_end, config.T)

        # Initialize training state
        self.step = 0
        self.params = None
        self.opt_state = None

    def _init_real_tokenizer(self):
        """Initialize real SentencePiece tokenizer"""
        try:
            import sentencepiece as spm
            from datasets import load_dataset

            # This would normally train the tokenizer
            # For now, using mock tokenizer
            logger.warning("Real tokenizer not implemented, using mock")
            return MockTokenizer(self.config.vocab_size)
        except ImportError:
            logger.warning("Missing dependencies for real data, using mock")
            return MockTokenizer(self.config.vocab_size)

    def _init_real_dataset(self):
        """Initialize real TinyStories dataset"""
        try:
            from datasets import load_dataset
            # Implementation would go here
            logger.warning("Real dataset not implemented, using mock")
            return MockDataset(self.config.vocab_size, self.config.seq_length)
        except ImportError:
            logger.warning("Missing dependencies for real data, using mock")
            return MockDataset(self.config.vocab_size, self.config.seq_length)

    def q_sample(self, x0, t, key):
        """Forward diffusion process - mask tokens with probability β_t"""
        batch_size = x0.shape[0]

        # Get beta for each sample in batch
        beta_t = self.betas[t]  # Shape: (batch_size,)

        # Generate random mask for each token
        mask = jax.random.bernoulli(key, beta_t[:, None], x0.shape)

        # Apply masking
        xt = jnp.where(mask, self.mask_id, x0)
        return xt

    def loss_fn(self, params, batch, rng, deterministic: bool = False):
        """Compute D3PM loss"""
        batch_size = batch.shape[0]

        # Sample random timesteps
        t_key, mask_key, model_key = jax.random.split(rng, 3)
        t = jax.random.randint(t_key, (batch_size,), 0, self.config.T)

        # Forward process
        xt = self.q_sample(batch, t, mask_key)

        # Predict original tokens
        if deterministic:
            logits = self.model.apply(
                {'params': params},
                xt, t,
                deterministic=True
            )
        else:
            logits = self.model.apply(
                {'params': params},
                xt, t,
                deterministic=False,
                rngs={'dropout': model_key}
            )

        # Compute cross-entropy loss only on masked positions
        mask_positions = (xt == self.mask_id)

        # Reshape for loss computation
        logits_flat = logits.reshape(-1, logits.shape[-1])
        targets_flat = batch.reshape(-1)
        mask_flat = mask_positions.reshape(-1)

        # Compute loss only on masked positions
        losses = optax.softmax_cross_entropy_with_integer_labels(
            logits_flat, targets_flat
        )

        # Average over masked positions
        masked_loss = jnp.where(mask_flat, losses, 0.0)

        # Use safe division to avoid division by zero
        num_masked = jnp.sum(mask_flat)
        safe_num_masked = jnp.maximum(num_masked, 1.0)  # Avoid division by zero

        return jnp.sum(masked_loss) / safe_num_masked

    def init_training(self, key):
        """Initialize training state"""
        # Initialize parameters
        dummy_batch = jnp.ones((1, self.config.seq_length), dtype=jnp.int32)
        dummy_t = jnp.zeros((1,), dtype=jnp.int32)

        # Initialize with deterministic=True to avoid needing dropout RNG
        variables = self.model.init(
            key,
            dummy_batch,
            dummy_t,
            deterministic=True
        )
        self.params = variables['params']

        # Initialize optimizer
        tx = optax.adamw(
            learning_rate=self.config.learning_rate,
            b1=0.9, b2=0.95,
            weight_decay=self.config.weight_decay
        )
        self.opt_state = tx.init(self.params)
        self.tx = tx

        logger.info(f"Model initialized with {self._count_params()/1e6:.1f}M parameters")

    def _count_params(self):
        """Count model parameters"""
        return sum(p.size for p in jax.tree_util.tree_leaves(self.params))

    @functools.partial(jax.jit, static_argnums=(0, 5))  # Make deterministic static
    def train_step(self, params, opt_state, batch, rng, deterministic=False):
        """Single training step"""
        loss, grads = jax.value_and_grad(self.loss_fn)(params, batch, rng, deterministic)
        updates, new_opt_state = self.tx.update(grads, opt_state, params)
        new_params = optax.apply_updates(params, updates)
        return new_params, new_opt_state, loss

    @functools.partial(jax.jit, static_argnums=(0,))
    def eval_step(self, params, batch):
        """Evaluation step"""
        # Use unconditional generation for evaluation with deterministic=True
        logits = self.model.apply(
            {'params': params},
            batch,
            jnp.zeros((batch.shape[0],), dtype=jnp.int32),
            deterministic=True
        )

        # Compute perplexity
        log_probs = jax.nn.log_softmax(logits, axis=-1)
        target_log_probs = jnp.take_along_axis(
            log_probs, batch[..., None], axis=-1
        ).squeeze(-1)

        # Mask out padding tokens (assuming 0 is padding)
        mask = batch != 0
        masked_log_probs = jnp.where(mask, target_log_probs, 0.0)

        avg_log_prob = jnp.sum(masked_log_probs) / jnp.sum(mask)
        bits_per_token = -avg_log_prob / jnp.log(2.0)

        return bits_per_token

    def get_data_loader(self):
        """Get batched data loader"""
        def batch_generator():
            batch = []
            for item in self.dataset:
                batch.append(item)
                if len(batch) == self.config.batch_size:
                    yield jnp.array(batch)
                    batch = []

        return batch_generator()

    def train(self, max_steps: Optional[int] = None):
        """Main training loop"""
        if self.params is None:
            self.init_training(jax.random.PRNGKey(42))

        max_steps = max_steps or self.config.max_steps
        data_loader = self.get_data_loader()

        logger.info(f"Starting training for {max_steps} steps")
        start_time = time.time()

        try:
            for step in range(max_steps):
                # Get batch
                try:
                    batch = next(data_loader)
                except StopIteration:
                    data_loader = self.get_data_loader()
                    batch = next(data_loader)

                # Training step
                rng = jax.random.fold_in(jax.random.PRNGKey(42), step)
                self.params, self.opt_state, loss = self.train_step(
                    self.params, self.opt_state, batch, rng, False  # deterministic=False
                )

                self.step += 1

                # Logging
                if step % self.config.log_every == 0:
                    elapsed = time.time() - start_time
                    tokens_per_sec = (step + 1) * self.config.batch_size * self.config.seq_length / elapsed
                    logger.info(
                        f"Step {step}: loss={loss:.4f}, "
                        f"tokens/sec={tokens_per_sec:.0f}"
                    )

                # Evaluation
                if step % self.config.eval_every == 0 and step > 0:
                    eval_batch = next(data_loader)
                    bpt = self.eval_step(self.params, eval_batch)
                    logger.info(f"Step {step}: validation bits/token={bpt:.2f}")

        except KeyboardInterrupt:
            logger.info("Training interrupted by user")

        logger.info("Training completed")

    def sample(self, n_samples: int = 1, guidance_scale: float = 1.0, seed: int = 42):
        """Generate samples using the trained model"""
        if self.params is None:
            raise ValueError("Model not trained yet")

        # Start with fully masked sequence
        samples = jnp.full(
            (n_samples, self.config.seq_length),
            self.mask_id,
            dtype=jnp.int32
        )

        # Iterative denoising
        base_key = jax.random.PRNGKey(seed)

        for t in reversed(range(self.config.T)):
            t_batch = jnp.full((n_samples,), t, dtype=jnp.int32)

            # Generate keys for this timestep
            step_key = jax.random.fold_in(base_key, t)
            sample_key = step_key

            # Get logits (use deterministic=True for sampling)
            logits = self.model.apply(
                {'params': self.params},
                samples, t_batch,
                deterministic=True
            )

            # Apply guidance if needed
            if guidance_scale != 1.0:
                # Unconditional logits
                uncond_logits = self.model.apply(
                    {'params': self.params},
                    samples,
                    jnp.zeros((n_samples,), dtype=jnp.int32),
                    deterministic=True
                )
                # Classifier-free guidance
                logits = uncond_logits + guidance_scale * (logits - uncond_logits)

            # Sample from logits
            new_tokens = jax.random.categorical(sample_key, logits)

            # Only update masked positions
            mask_positions = (samples == self.mask_id)
            samples = jnp.where(mask_positions, new_tokens, samples)

        return samples

# Testing utilities
class TestD3PM:
    """Test suite for D3PM implementation"""

    def __init__(self):
        self.config = D3PMConfig(
            vocab_size=1000,
            seq_length=64,
            d_model=128,
            n_heads=4,
            n_layers=2,
            d_ff=256,
            T=4,
            batch_size=8,
            max_steps=100
        )

    def test_model_forward(self):
        """Test model forward pass"""
        print("Testing model forward pass...")

        trainer = D3PMTrainer(self.config, use_mock_data=True)
        trainer.init_training(jax.random.PRNGKey(0))

        # Test forward pass
        batch = jnp.ones((4, self.config.seq_length), dtype=jnp.int32)
        t = jnp.zeros((4,), dtype=jnp.int32)

        logits = trainer.model.apply(
            {'params': trainer.params},
            batch, t,
            deterministic=True
        )

        expected_shape = (4, self.config.seq_length, self.config.vocab_size)
        assert logits.shape == expected_shape, f"Expected {expected_shape}, got {logits.shape}"
        print("✓ Model forward pass test passed")

    def test_loss_computation(self):
        """Test loss computation"""
        print("Testing loss computation...")

        trainer = D3PMTrainer(self.config, use_mock_data=True)
        trainer.init_training(jax.random.PRNGKey(0))

        batch = jax.random.randint(
            jax.random.PRNGKey(1),
            (4, self.config.seq_length),
            1, self.config.vocab_size - 1
        )

        loss = trainer.loss_fn(trainer.params, batch, jax.random.PRNGKey(2), deterministic=False)

        assert jnp.isfinite(loss), f"Loss is not finite: {loss}"
        assert loss >= 0, f"Loss should be non-negative: {loss}"
        print(f"✓ Loss computation test passed (loss={loss:.4f})")

    def test_training_step(self):
        """Test training step"""
        print("Testing training step...")

        trainer = D3PMTrainer(self.config, use_mock_data=True)
        trainer.init_training(jax.random.PRNGKey(0))

        batch = jax.random.randint(
            jax.random.PRNGKey(1),
            (self.config.batch_size, self.config.seq_length),
            1, self.config.vocab_size - 1
        )

        old_params = trainer.params
        trainer.params, trainer.opt_state, loss = trainer.train_step(
            trainer.params, trainer.opt_state, batch, jax.random.PRNGKey(2), False  # deterministic=False
        )

        # Check that parameters changed
        param_changed = False
        for old_p, new_p in zip(
            jax.tree_util.tree_leaves(old_params),
            jax.tree_util.tree_leaves(trainer.params)
        ):
            if not jnp.allclose(old_p, new_p):
                param_changed = True
                break

        assert param_changed, "Parameters should change after training step"
        print(f"✓ Training step test passed (loss={loss:.4f})")

    def test_sampling(self):
        """Test sampling"""
        print("Testing sampling...")

        trainer = D3PMTrainer(self.config, use_mock_data=True)
        trainer.init_training(jax.random.PRNGKey(0))

        samples = trainer.sample(n_samples=2)

        expected_shape = (2, self.config.seq_length)
        assert samples.shape == expected_shape, f"Expected {expected_shape}, got {samples.shape}"

        # Check that samples are valid token IDs
        assert jnp.all(samples >= 0), "All token IDs should be non-negative"
        assert jnp.all(samples < self.config.vocab_size), "All token IDs should be < vocab_size"

        print("✓ Sampling test passed")

    def test_full_pipeline(self):
        """Test full training pipeline"""
        print("Testing full pipeline...")

        trainer = D3PMTrainer(self.config, use_mock_data=True)
        trainer.train(max_steps=50)

        # Test that we can sample after training
        samples = trainer.sample(n_samples=1)
        print("✓ Full pipeline test passed")

    def run_all_tests(self):
        """Run all tests"""
        print("Running D3PM tests...")
        print("=" * 50)

        tests = [
            self.test_model_forward,
            self.test_loss_computation,
            self.test_training_step,
            self.test_sampling,
            self.test_full_pipeline
        ]

        passed = 0
        for test in tests:
            try:
                test()
                passed += 1
            except Exception as e:
                print(f"✗ {test.__name__} failed: {e}")

        print("=" * 50)
        print(f"Tests passed: {passed}/{len(tests)}")
        return passed == len(tests)

def simulate_training():
    """Simulate a training run"""
    print("Simulating D3PM training...")
    print("=" * 50)

    # Use smaller config for simulation
    config = D3PMConfig(
        vocab_size=1000,
        seq_length=128,
        d_model=256,
        n_heads=8,
        n_layers=4,
        d_ff=512,
        T=8,
        batch_size=16,
        max_steps=1000,
        log_every=50,
        eval_every=200
    )

    trainer = D3PMTrainer(config, use_mock_data=True)

    # Train for a short time
    trainer.train(max_steps=500)

    # Generate some samples
    print("\nGenerating samples...")
    samples = trainer.sample(n_samples=3)

    for i, sample in enumerate(samples):
        decoded = trainer.tokenizer.decode(sample.tolist())
        print(f"Sample {i+1}: {decoded[:100]}...")

    print("\nSimulation completed!")

# Check if JAX is available
try:
    import jax
    print(f"JAX version: {jax.__version__}")
    print(f"Available devices: {jax.devices()}")
except ImportError:
    print("JAX not available, some tests may fail")

# Run tests
test_suite = TestD3PM()
all_passed = test_suite.run_all_tests()

if all_passed:
    print("\nAll tests passed! Running simulation...")
    simulate_training()
else:
    print("\nSome tests failed. Please check the implementation.")

"""## 1.2 AdvancedD3PMTrainer with Synthetic data training (integration testing)

```python
trainer, history = run_full_training()
```

Sample output:
```
🎯 Starting Full D3PM Training on TPU
============================================================
🔧 Configuration:
   Vocab size: 2,048
   Sequence length: 256
   Model dimension: 512
   Layers: 8
   Heads: 8
   Diffusion steps: 16
   Batch size: 32
   Learning rate: 0.0001
🚀 Starting D3PM **Training**
📊 Model: 27.5M parameters
🎯 Training for 8 epochs (1000 steps each)
📈 Total steps: 8,000
💾 Batch size: 32
🔧 Device: TPU_0(process=0,(0,0,0,0))
============================================================

📅 Epoch 1/8
```

## 1.2b Code Explanation

This code defines an **`AdvancedD3PMTrainer`** which extends the base `D3PMTrainer` to include enhanced logging and monitoring features, along with a configuration specifically designed for training on a TPU.

---

## Key Features & Components

* **`create_training_config()`**: This function sets up a more realistic configuration for TPU training. It defines larger model dimensions (`d_model`, `n_layers`, `d_ff`), an increased vocabulary size, more diffusion steps (`T`), and training parameters (like batch size and learning rate) optimized for a TPU environment.

* **`AdvancedD3PMTrainer(D3PMTrainer)`**: This class inherits from the original `D3PMTrainer` and adds key monitoring capabilities:
    * It maintains a `training_history` to store metrics like training and evaluation loss over time.
    * It tracks `best_loss` to save the model with the best validation performance.

* **`train_with_monitoring()`**: This is the main training loop for the advanced trainer. It iterates through training steps and includes:
    * **Detailed Logging**: Prints the configuration, progress, loss, and tokens per second periodically.
    * **Periodic Evaluation**: Runs quick evaluations using `_quick_eval()` to estimate the validation loss (Bits per Token).
    * **Progress Visualization**: Optionally shows a generated sample during training via `_show_training_sample()`.
    * **Epoch Summaries**: Provides a summary of average loss and time at the end of each epoch.
    * **Graceful Shutdown**: Handles `KeyboardInterrupt` to stop training cleanly.

* **`_quick_eval()`**: A helper function that performs a quick evaluation on a few batches to estimate the validation loss.

* **`_show_training_sample()`**: Generates and prints a decoded sample from the model during training to visualize its progress.

* **`plot_training_curves()`**: A function to visualize the training process by plotting training loss, validation loss, and other metrics over time. 📊

* **`generate_samples()`**: Generates and prints multiple decoded samples after training is complete to assess the final model's output.

* **`run_full_training()`**: This function orchestrates the entire workflow. It initializes the trainer, runs the `train_with_monitoring` loop, plots the training curves, and generates final samples.

---

## Overall Purpose

The goal of this code is to create a more robust and observable training setup for the D3PM model, making it easier to monitor progress, debug, and evaluate performance, especially when running on a TPU.
"""

# D3PM Full Training Script - Optimized for TPU
import jax
import jax.numpy as jnp
import time
import matplotlib.pyplot as plt
from collections import defaultdict
import numpy as np

def create_training_config():
    """Create a realistic training configuration for TPU"""
    return D3PMConfig(
        # Model architecture - larger for better results
        vocab_size=2048,
        seq_length=256,
        d_model=512,
        n_heads=8,
        n_layers=8,
        d_ff=2048,
        dropout_rate=0.1,

        # Diffusion parameters
        T=16,
        beta_start=0.0001,
        beta_end=0.02,

        # Training parameters - optimized for TPU
        batch_size=32,  # Good size for TPU
        learning_rate=1e-4,
        weight_decay=1e-2,
        max_steps=50_000,
        log_every=250,      # Less frequent logging
        eval_every=2500,    # Less frequent evaluation
        save_every=10_000
    )

class AdvancedD3PMTrainer(D3PMTrainer):
    """Enhanced trainer with better logging and monitoring"""

    def __init__(self, config, use_mock_data=True):
        super().__init__(config, use_mock_data)
        self.training_history = defaultdict(list)
        self.best_loss = float('inf')

    def train_with_monitoring(self, num_epochs: int = 10, steps_per_epoch: int = 1000):
        """Train with epoch-based monitoring"""
        if self.params is None:
            self.init_training(jax.random.PRNGKey(42))

        data_loader = self.get_data_loader()
        total_steps = num_epochs * steps_per_epoch

        print(f"🚀 Starting D3PM Training")
        print(f"📊 Model: {self._count_params()/1e6:.1f}M parameters")
        print(f"🎯 Training for {num_epochs} epochs ({steps_per_epoch} steps each)")
        print(f"📈 Total steps: {total_steps:,}")
        print(f"💾 Batch size: {self.config.batch_size}")
        print(f"🔧 Device: {jax.devices()[0]}")
        print("=" * 60)

        start_time = time.time()
        step = 0

        try:
            for epoch in range(num_epochs):
                epoch_start = time.time()
                epoch_losses = []

                print(f"\n📅 Epoch {epoch + 1}/{num_epochs}")

                for step_in_epoch in range(steps_per_epoch):
                    # Get batch
                    try:
                        batch = next(data_loader)
                    except StopIteration:
                        data_loader = self.get_data_loader()
                        batch = next(data_loader)

                    # Training step
                    rng = jax.random.fold_in(jax.random.PRNGKey(42), step)
                    self.params, self.opt_state, loss = self.train_step(
                        self.params, self.opt_state, batch, rng, False
                    )

                    epoch_losses.append(float(loss))
                    step += 1

                    # Periodic logging during epoch
                    if step % self.config.log_every == 0:
                        elapsed = time.time() - start_time
                        tokens_per_sec = step * self.config.batch_size * self.config.seq_length / elapsed
                        avg_loss = np.mean(epoch_losses[-50:]) if epoch_losses else loss

                        print(f"  Step {step:5d} | Loss: {avg_loss:.4f} | "
                              f"Tokens/sec: {tokens_per_sec:8.0f} | "
                              f"Time: {elapsed/60:.1f}min")

                    # Evaluation
                    if step % self.config.eval_every == 0 and step > 0:
                        eval_loss = self._quick_eval()
                        self.training_history['eval_loss'].append(eval_loss)
                        self.training_history['eval_steps'].append(step)

                        if eval_loss < self.best_loss:
                            self.best_loss = eval_loss
                            print(f"  🎉 New best validation loss: {eval_loss:.4f}")

                        # Generate sample during training
                        if step % (self.config.eval_every * 2) == 0:
                            self._show_training_sample()

                # Epoch summary
                epoch_time = time.time() - epoch_start
                avg_epoch_loss = np.mean(epoch_losses)
                self.training_history['epoch_loss'].append(avg_epoch_loss)
                self.training_history['epoch_time'].append(epoch_time)

                print(f"✅ Epoch {epoch + 1} completed:")
                print(f"   Average Loss: {avg_epoch_loss:.4f}")
                print(f"   Time: {epoch_time/60:.1f} minutes")
                print(f"   Steps/sec: {steps_per_epoch/epoch_time:.1f}")

        except KeyboardInterrupt:
            print("\n⏹️  Training interrupted by user")

        total_time = time.time() - start_time
        print(f"\n🏁 Training completed!")
        print(f"   Total time: {total_time/60:.1f} minutes")
        print(f"   Final loss: {epoch_losses[-1]:.4f}")
        print(f"   Best validation loss: {self.best_loss:.4f}")

        return self.training_history

    def _quick_eval(self, num_batches: int = 5):
        """Quick evaluation on a few batches"""
        data_loader = self.get_data_loader()
        eval_losses = []

        for _ in range(num_batches):
            try:
                batch = next(data_loader)
            except StopIteration:
                data_loader = self.get_data_loader()
                batch = next(data_loader)

            bpt = self.eval_step(self.params, batch)
            eval_losses.append(float(bpt))

        return np.mean(eval_losses)

    def _show_training_sample(self):
        """Generate and show a training sample"""
        samples = self.sample(n_samples=1, seed=int(time.time()))
        decoded = self.tokenizer.decode(samples[0].tolist())
        print(f"  📝 Sample: {decoded[:80]}...")

    def plot_training_curves(self):
        """Plot training curves"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))

        # Training loss
        if self.training_history['epoch_loss']:
            axes[0, 0].plot(self.training_history['epoch_loss'])
            axes[0, 0].set_title('Training Loss per Epoch')
            axes[0, 0].set_xlabel('Epoch')
            axes[0, 0].set_ylabel('Loss')
            axes[0, 0].grid(True)

        # Validation loss
        if self.training_history['eval_loss']:
            axes[0, 1].plot(self.training_history['eval_steps'],
                           self.training_history['eval_loss'])
            axes[0, 1].set_title('Validation Loss')
            axes[0, 1].set_xlabel('Step')
            axes[0, 1].set_ylabel('Bits per Token')
            axes[0, 1].grid(True)

        # Training time per epoch
        if self.training_history['epoch_time']:
            axes[1, 0].plot(self.training_history['epoch_time'])
            axes[1, 0].set_title('Training Time per Epoch')
            axes[1, 0].set_xlabel('Epoch')
            axes[1, 0].set_ylabel('Time (seconds)')
            axes[1, 0].grid(True)

        # Tokens per second (calculated)
        if len(self.training_history['epoch_time']) > 0:
            steps_per_epoch = 1000  # From training
            tokens_per_epoch = steps_per_epoch * self.config.batch_size * self.config.seq_length
            tokens_per_sec = [tokens_per_epoch / t for t in self.training_history['epoch_time']]
            axes[1, 1].plot(tokens_per_sec)
            axes[1, 1].set_title('Training Throughput')
            axes[1, 1].set_xlabel('Epoch')
            axes[1, 1].set_ylabel('Tokens/sec')
            axes[1, 1].grid(True)

        plt.tight_layout()
        plt.show()

    def generate_samples(self, num_samples: int = 5, max_length: int = 100):
        """Generate and display multiple samples"""
        print(f"\n🎭 Generating {num_samples} samples:")
        print("=" * 60)

        samples = self.sample(n_samples=num_samples)

        for i, sample in enumerate(samples):
            decoded = self.tokenizer.decode(sample.tolist())
            # Clean up the output
            words = decoded.split()[:20]  # First 20 words
            clean_text = " ".join(words)
            print(f"Sample {i+1:2d}: {clean_text}")

        print("=" * 60)

def run_full_training():
    """Run the full training pipeline"""
    # Create configuration
    config = create_training_config()

    print("🔧 Configuration:")
    print(f"   Vocab size: {config.vocab_size:,}")
    print(f"   Sequence length: {config.seq_length}")
    print(f"   Model dimension: {config.d_model}")
    print(f"   Layers: {config.n_layers}")
    print(f"   Heads: {config.n_heads}")
    print(f"   Diffusion steps: {config.T}")
    print(f"   Batch size: {config.batch_size}")
    print(f"   Learning rate: {config.learning_rate}")

    # Create trainer
    trainer = AdvancedD3PMTrainer(config, use_mock_data=True)

    # Train the model
    history = trainer.train_with_monitoring(
        num_epochs=8,      # Reasonable number of epochs
        steps_per_epoch=1000  # Steps per epoch
    )

    # Show results
    print("\n📊 Plotting training curves...")
    trainer.plot_training_curves()

    # Generate samples
    trainer.generate_samples(num_samples=8)

    # Final statistics
    print(f"\n📈 Training Statistics:")
    if history['epoch_loss']:
        print(f"   Initial loss: {history['epoch_loss'][0]:.4f}")
        print(f"   Final loss: {history['epoch_loss'][-1]:.4f}")
        print(f"   Loss reduction: {history['epoch_loss'][0] - history['epoch_loss'][-1]:.4f}")

    if history['eval_loss']:
        print(f"   Best validation loss: {min(history['eval_loss']):.4f}")

    if history['epoch_time']:
        avg_time = np.mean(history['epoch_time'])
        print(f"   Average time per epoch: {avg_time/60:.1f} minutes")

    return trainer, history

# Run the training
print("🎯 Starting Full D3PM Training on TPU")
print("=" * 60)
trainer, history = run_full_training()

"""## 1.3 TPU Monitoring and verification

```python
quick_tpu_check()

# Full verification:
verify_tpu_setup()
benchmark_tpu_vs_cpu()

#. Training with monitoring:
trainer, history = train_with_tpu_monitoring(log_every=200, num_epochs=2, steps_per_epoch=500)

# 📊 What to look for:
# ✅ JAX backend shows 'tpu'
# ✅ Fast computation times (<0.1s for large matrices)
# ✅ Low CPU usage during training (<20%)
# ✅ High tokens/sec throughput (>30k for v6e1)
# ✅ Training efficiency >80%

# ❌ Warning signs:
# - High CPU usage during training
# - Slow computation times
# - Low tokens/sec throughput
# - Training efficiency <50%
````

## 1.3b Code explanation

This code provides a suite of tools for monitoring and verifying TPU usage and performance in Google Colab, specifically targeting the v6e1 architecture. 📈

---

## Key Components

* **`TPUMonitor` Class**: This class is designed to monitor system resources (CPU and memory) during a training run.
    * `start_monitoring()`: Starts a background thread that periodically records CPU and memory usage.
    * `stop_monitoring()`: Stops the monitoring thread.
    * `_monitor_loop()`: The background loop that collects system resource data using the `psutil` library.
    * `plot_usage()`: Generates plots of the collected CPU and memory usage over time. It provides a basic analysis to indicate whether the TPU is likely being utilized effectively.

* **`verify_tpu_setup()` Function**: Performs a comprehensive check to ensure the TPU is set up correctly. It confirms that a TPU is detected, attempts to retrieve memory statistics, and runs a small benchmark using JAX's `jit` to verify that computations are being offloaded to the TPU.

* **`benchmark_tpu_vs_cpu()` Function**: Compares the performance of a matrix multiplication operation on the TPU versus the CPU and calculates the speedup achieved.

* **`monitor_training_performance()` Function**: Estimates the potential training throughput (tokens per second) by benchmarking a simplified dummy training step. It then compares this measured throughput against the expected performance for a v6e1 TPU to assess potential bottlenecks.

* **`check_tpu_memory_usage()` Function**: Attempts to get detailed TPU memory statistics and tests the ability to allocate large arrays to get an indication of available TPU memory.

* **`train_with_tpu_monitoring()` Function**: This function wraps an entire training process.
    * It first runs all the verification and benchmark checks.
    * It starts the **`TPUMonitor`** before training begins.
    * It runs the actual training process.
    * Finally, it stops the **`TPUMonitor`** and plots the resource usage, reporting the actual training throughput and efficiency.

* **`quick_tpu_check()` Function**: A simplified, fast check to confirm the JAX backend and devices. It runs a small matrix test to see if the TPU is responsive. This is intended to be run as a first step.

---

## Summary & Usage

The code also includes usage instructions explaining how to use these functions for quick checks, full verification, and monitoring a training run. The overall goal is to provide a comprehensive toolkit for diagnosing potential issues with TPU setup and performance in Google Colab.
"""

# TPU Monitoring and Verification Tools for Google Colab v6e1

import jax
import jax.numpy as jnp
import time
import psutil
import threading
import matplotlib.pyplot as plt
from collections import deque
import subprocess
import json

class TPUMonitor:
    """Monitor TPU usage during training"""

    def __init__(self):
        self.cpu_usage = deque(maxlen=100)
        self.memory_usage = deque(maxlen=100)
        self.timestamps = deque(maxlen=100)
        self.monitoring = False
        self.monitor_thread = None

    def start_monitoring(self):
        """Start monitoring system resources"""
        self.monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitor_loop)
        self.monitor_thread.start()
        print("🔍 Started system monitoring...")

    def stop_monitoring(self):
        """Stop monitoring"""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join()
        print("⏹️  Stopped monitoring")

    def _monitor_loop(self):
        """Background monitoring loop"""
        while self.monitoring:
            self.cpu_usage.append(psutil.cpu_percent())
            self.memory_usage.append(psutil.virtual_memory().percent)
            self.timestamps.append(time.time())
            time.sleep(2)  # Monitor every 2 seconds

    def plot_usage(self):
        """Plot CPU and memory usage"""
        if len(self.cpu_usage) < 2:
            print("Not enough data to plot")
            return

        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))

        times = [(t - self.timestamps[0])/60 for t in self.timestamps]

        ax1.plot(times, list(self.cpu_usage), 'b-', label='CPU %')
        ax1.set_ylabel('CPU Usage (%)')
        ax1.set_title('System Resource Usage During Training')
        ax1.grid(True)
        ax1.legend()

        ax2.plot(times, list(self.memory_usage), 'r-', label='Memory %')
        ax2.set_ylabel('Memory Usage (%)')
        ax2.set_xlabel('Time (minutes)')
        ax2.grid(True)
        ax2.legend()

        plt.tight_layout()
        plt.show()

        # Analysis
        avg_cpu = sum(self.cpu_usage) / len(self.cpu_usage)
        print(f"\n📊 Resource Usage Analysis:")
        print(f"   Average CPU: {avg_cpu:.1f}%")
        if avg_cpu < 20:
            print("   ✅ Low CPU usage suggests TPU is doing the work!")
        elif avg_cpu > 50:
            print("   ⚠️  High CPU usage - might be running on CPU instead of TPU")

def verify_tpu_setup():
    """Comprehensive TPU verification"""
    print("🔧 TPU Setup Verification")
    print("=" * 50)

    # 1. Check JAX backend and devices
    print(f"JAX version: {jax.__version__}")
    print(f"JAX backend: {jax.default_backend()}")

    devices = jax.devices()
    print(f"Available devices: {devices}")

    if not devices or 'tpu' not in str(devices[0]).lower():
        print("❌ TPU not detected! You might be using CPU/GPU")
        return False

    print(f"✅ TPU detected: {devices[0]}")

    # 2. Check device memory
    try:
        device_memory = jax.devices()[0].memory_stats()
        print(f"TPU memory stats: {device_memory}")
    except:
        print("⚠️  Could not get TPU memory stats")

    # 3. Test computation placement
    print("\n🧪 Testing computation placement...")

    @jax.jit
    def test_computation(x):
        return jnp.sum(x ** 2)

    # Create large array to ensure it goes to TPU
    x = jax.random.normal(jax.random.PRNGKey(0), (10000, 1000))

    # Time the computation
    start = time.time()
    result = test_computation(x)
    result.block_until_ready()  # Ensure computation is complete
    tpu_time = time.time() - start

    print(f"Large matrix computation time: {tpu_time:.4f}s")
    if tpu_time < 0.1:
        print("✅ Fast computation suggests TPU usage")
    else:
        print("⚠️  Slow computation might indicate CPU usage")

    return True

def benchmark_tpu_vs_cpu():
    """Benchmark TPU vs CPU performance"""
    print("\n⚡ TPU vs CPU Benchmark")
    print("=" * 50)

    # Test computation
    def matmul_test(backend):
        if backend == 'cpu':
            with jax.default_device(jax.devices('cpu')[0] if jax.devices('cpu') else jax.devices()[0]):
                x = jax.random.normal(jax.random.PRNGKey(0), (2000, 2000))
                y = jax.random.normal(jax.random.PRNGKey(1), (2000, 2000))

                start = time.time()
                result = jnp.dot(x, y)
                result.block_until_ready()
                return time.time() - start
        else:
            x = jax.random.normal(jax.random.PRNGKey(0), (2000, 2000))
            y = jax.random.normal(jax.random.PRNGKey(1), (2000, 2000))

            start = time.time()
            result = jnp.dot(x, y)
            result.block_until_ready()
            return time.time() - start

    # Run benchmarks
    try:
        tpu_time = matmul_test('tpu')
        print(f"TPU matmul time: {tpu_time:.4f}s")

        if jax.devices('cpu'):
            cpu_time = matmul_test('cpu')
            print(f"CPU matmul time: {cpu_time:.4f}s")
            speedup = cpu_time / tpu_time
            print(f"TPU speedup: {speedup:.1f}x")

            if speedup > 2:
                print("✅ Significant TPU speedup detected!")
            else:
                print("⚠️  Low speedup - check TPU utilization")
        else:
            print("ℹ️  CPU devices not available for comparison")

    except Exception as e:
        print(f"❌ Benchmark failed: {e}")

def monitor_training_performance():
    """Monitor performance indicators during training"""
    print("\n📈 Training Performance Indicators")
    print("=" * 50)

    # Get baseline metrics
    print("Checking baseline performance...")

    # Create a simple training step to test
    def dummy_train_step():
        # Simulate model forward pass
        x = jax.random.normal(jax.random.PRNGKey(0), (32, 256, 512))  # batch, seq, dim
        w = jax.random.normal(jax.random.PRNGKey(1), (512, 8000))     # weights

        # Matrix multiply (common in transformers)
        logits = jnp.dot(x, w)
        loss = jnp.mean(logits ** 2)
        return loss

    # JIT compile
    jitted_step = jax.jit(dummy_train_step)

    # Warmup
    for _ in range(3):
        _ = jitted_step()

    # Time multiple steps
    times = []
    for i in range(10):
        start = time.time()
        loss = jitted_step()
        loss.block_until_ready()
        step_time = time.time() - start
        times.append(step_time)

    avg_time = sum(times) / len(times)
    tokens_per_sec = (32 * 256) / avg_time  # batch_size * seq_length / time

    print(f"Average step time: {avg_time*1000:.2f}ms")
    print(f"Tokens per second: {tokens_per_sec:.0f}")

    # Performance expectations for v6e1
    expected_tokens_per_sec = 50000  # Rough estimate for v6e1

    if tokens_per_sec > expected_tokens_per_sec * 0.7:
        print("✅ Good performance - likely using TPU effectively")
    elif tokens_per_sec > expected_tokens_per_sec * 0.3:
        print("⚠️  Moderate performance - check for bottlenecks")
    else:
        print("❌ Poor performance - likely CPU fallback or inefficient code")

    return avg_time, tokens_per_sec

def check_tpu_memory_usage():
    """Check TPU memory usage"""
    print("\n💾 TPU Memory Usage")
    print("=" * 50)

    try:
        # Create arrays of different sizes to test memory
        arrays = []
        for i in range(5):
            size = (1000, 1000)
            arr = jax.random.normal(jax.random.PRNGKey(i), size)
            arrays.append(arr)

        # Try to get memory stats
        device = jax.devices()[0]
        if hasattr(device, 'memory_stats'):
            stats = device.memory_stats()
            print(f"Memory stats: {stats}")
        else:
            print("Memory stats not available for this device")

        # Check if we can allocate large arrays (TPU has more memory than typical GPU)
        try:
            large_array = jax.random.normal(jax.random.PRNGKey(0), (10000, 10000))
            print("✅ Successfully allocated large array - TPU memory available")
            del large_array
        except Exception as e:
            print(f"⚠️  Large array allocation failed: {e}")

    except Exception as e:
        print(f"❌ Memory check failed: {e}")

# Enhanced training function with TPU monitoring
def train_with_tpu_monitoring(log_every: int = 200, num_epochs: int = 2, steps_per_epoch: int = 500):
    """Train with comprehensive TPU monitoring"""

    print("🔍 Starting TPU-monitored training...")

    # Run all verification checks
    if not verify_tpu_setup():
        print("❌ TPU setup verification failed!")
        return None, None

    benchmark_tpu_vs_cpu()
    avg_time, tokens_per_sec = monitor_training_performance()
    check_tpu_memory_usage()

    # Start system monitoring
    monitor = TPUMonitor()
    monitor.start_monitoring()

    try:
        # Run actual training
        trainer, history = train_on_real_data(
            log_every=log_every,
            num_epochs=num_epochs,
            steps_per_epoch=steps_per_epoch
        )

        print(f"\n📊 Training completed!")
        print(f"Expected tokens/sec: {tokens_per_sec:.0f}")

        # Calculate actual training throughput
        if history['epoch_time']:
            total_tokens = num_epochs * steps_per_epoch * 32 * 256  # epochs * steps * batch * seq
            total_time = sum(history['epoch_time'])
            actual_tokens_per_sec = total_tokens / total_time
            print(f"Actual training tokens/sec: {actual_tokens_per_sec:.0f}")

            efficiency = actual_tokens_per_sec / tokens_per_sec * 100
            print(f"Training efficiency: {efficiency:.1f}%")

            if efficiency > 80:
                print("✅ Excellent TPU utilization!")
            elif efficiency > 50:
                print("⚠️  Good TPU utilization")
            else:
                print("❌ Poor TPU utilization - check for bottlenecks")

        return trainer, history

    finally:
        # Stop monitoring and show results
        monitor.stop_monitoring()
        monitor.plot_usage()

# Simple verification function to run first
def quick_tpu_check():
    """Quick TPU verification - run this first"""
    print("🚀 Quick TPU Check")
    print("=" * 30)

    print(f"JAX backend: {jax.default_backend()}")
    print(f"Devices: {jax.devices()}")

    if 'tpu' in str(jax.devices()[0]).lower():
        print("✅ TPU detected!")

        # Quick performance test
        x = jax.random.normal(jax.random.PRNGKey(0), (5000, 5000))
        start = time.time()
        result = jnp.sum(x @ x)
        result.block_until_ready()
        elapsed = time.time() - start

        print(f"⚡ Matrix test: {elapsed:.3f}s")
        if elapsed < 0.5:
            print("✅ Fast computation - TPU working!")
        else:
            print("⚠️  Slow computation - might be CPU")
    else:
        print("❌ No TPU detected")

# Usage instructions
print("""
🔍 TPU Monitoring Tools:

1. Quick check (run this first):
   quick_tpu_check()

2. Full verification:
   verify_tpu_setup()
   benchmark_tpu_vs_cpu()

3. Training with monitoring:
   trainer, history = train_with_tpu_monitoring(log_every=200, num_epochs=2, steps_per_epoch=500)

📊 What to look for:
✅ JAX backend shows 'tpu'
✅ Fast computation times (<0.1s for large matrices)
✅ Low CPU usage during training (<20%)
✅ High tokens/sec throughput (>30k for v6e1)
✅ Training efficiency >80%

❌ Warning signs:
- High CPU usage during training
- Slow computation times
- Low tokens/sec throughput
- Training efficiency <50%
""")

"""## 1.4 TPU BATCH Size Optimization for D3PM Model

```python
find_optimal_batch_size()
```

Sample output:
```
🎯 TPU Batch Size Optimization:

1. Check memory estimates:
   find_optimal_batch_size()

2. Benchmark performance:
   benchmark_batch_sizes()

3. See optimized configs:
   create_optimized_configs()

4. Train with larger batch:
   trainer, history = train_with_optimal_batch_size('large')  # batch_size=128

5. Compare multiple batch sizes:
   results = compare_batch_sizes()

💡 Quick recommendations for your setup:
- Current: batch_size=32 (only 4.5% memory usage!)
- Try: batch_size=128 (should use ~15-20% memory)
- Max: batch_size=512+ (if you want to push limits)

⚠️  Remember: Larger batch = higher learning rate needed!

🔍 Memory Usage Estimation for Different Batch Sizes:
============================================================
Available TPU memory: ~32GB

Batch size   32:   0.6GB ( 1.9% utilization) ✅
Batch size   64:   1.2GB ( 3.8% utilization) ✅
Batch size  128:   2.4GB ( 7.5% utilization) ✅
Batch size  256:   4.8GB (15.1% utilization) ✅
Batch size  512:   9.7GB (30.2% utilization) ✅
Batch size 1024:  19.3GB (60.4% utilization) ✅

📊 Recommendations:
✅ Safe: <80% memory utilization
⚠️  Risky: 80-100% utilization
❌ Too large: >100% utilization
```

## 1.4b Code Explanation

This code provides tools to estimate and benchmark the impact of different batch sizes on TPU memory usage and performance for a D3PM model. ⚙️

---

## Key Components

* **`estimate_memory_usage()`**: This function gives a rough estimate of the memory required for a D3PM model's parameters and activations during training.
    * It calculates memory based on batch size, sequence length, model dimension, and vocabulary size.
    * It includes estimates for token embeddings, attention matrices, activations, and output logits.

* **`find_optimal_batch_size()`**: This function uses `estimate_memory_usage()` to show the estimated memory utilization for various batch sizes.
    * It prints a table showing each batch size, its estimated memory usage in GB, and the percentage of TPU memory it would consume.
    * It provides recommendations (**Safe**, **Risky**, or **Too large**) based on the utilization percentage.

* **`benchmark_batch_sizes()`**: This function benchmarks the actual performance (in tokens per second) of a simplified forward pass for different batch sizes.
    * It uses JAX's `jit` to compile a dummy function for efficient execution on the TPU.
    * It measures step time and tokens per second for each benchmarked batch size.

* **`create_optimized_configs()`**: This function defines a base model configuration and then creates several optimized configurations with different batch sizes and adjusted learning rates. The learning rates are scaled based on common practices for larger batches.

* **`train_with_optimal_batch_size()`**: This function is intended to run a full training process using one of the optimized configurations.
    * It retrieves a specified configuration by name.
    * It includes placeholders to set up the real dataset and trainer.
    * It runs the training process and generates samples.
    * It includes warnings about potential issues with very large batch sizes, such as the need for learning rate warmup or gradient clipping.
    * **Note**: This function relies on other components (`SentencePieceTokenizer`, `RealTinyStoriesDataset`, etc.) that are assumed to be defined elsewhere.

* **`compare_batch_sizes()`**: Runs the `train_with_optimal_batch_size` function for a few predefined configurations ('small', 'medium', 'large') to compare their final performance and prints a summary of the results.

---

## Overall Approach

This code provides a structured way to analyze the memory limits and performance characteristics of different batch sizes on a TPU. It helps in generating optimized training configurations based on this analysis before committing to a full, time-consuming training run.
"""

# TPU Batch Size Optimization for D3PM

import jax
import jax.numpy as jnp
import time

def estimate_memory_usage(batch_size, seq_length=256, d_model=512, vocab_size=8000):
    """Estimate memory usage for different batch sizes"""

    # Rough memory estimates (in bytes)
    # Token embeddings: batch_size * seq_length * d_model * 4 bytes (float32)
    token_embeddings = batch_size * seq_length * d_model * 4

    # Attention matrices: batch_size * n_heads * seq_length^2 * 4 bytes
    n_heads = 8
    attention_memory = batch_size * n_heads * seq_length * seq_length * 4

    # Activations (rough estimate for transformer)
    n_layers = 6
    activation_memory = batch_size * seq_length * d_model * n_layers * 4 * 3  # 3x for gradients

    # Output logits: batch_size * seq_length * vocab_size * 4
    output_logits = batch_size * seq_length * vocab_size * 4

    total_mb = (token_embeddings + attention_memory + activation_memory + output_logits) / (1024 * 1024)
    return total_mb

def find_optimal_batch_size(available_memory_gb=32):
    """Find optimal batch size for TPU"""

    print("🔍 Memory Usage Estimation for Different Batch Sizes:")
    print("=" * 60)
    print(f"Available TPU memory: ~{available_memory_gb}GB")
    print()

    batch_sizes = [32, 64, 128, 256, 512, 1024]

    for batch_size in batch_sizes:
        memory_mb = estimate_memory_usage(batch_size)
        memory_gb = memory_mb / 1024
        utilization = (memory_gb / available_memory_gb) * 100

        status = "✅" if memory_gb < available_memory_gb * 0.8 else "⚠️" if memory_gb < available_memory_gb else "❌"

        print(f"Batch size {batch_size:4d}: {memory_gb:5.1f}GB ({utilization:4.1f}% utilization) {status}")

    print()
    print("📊 Recommendations:")
    print("✅ Safe: <80% memory utilization")
    print("⚠️  Risky: 80-100% utilization")
    print("❌ Too large: >100% utilization")

def benchmark_batch_sizes():
    """Benchmark different batch sizes"""
    print("\n⚡ Batch Size Performance Benchmark:")
    print("=" * 50)

    batch_sizes = [32, 64, 128, 256]
    seq_length = 256
    d_model = 512

    def dummy_forward(batch_size):
        # Simulate transformer forward pass
        x = jax.random.normal(jax.random.PRNGKey(0), (batch_size, seq_length, d_model))

        # Attention-like operation
        q = jnp.dot(x, jax.random.normal(jax.random.PRNGKey(1), (d_model, d_model)))
        k = jnp.dot(x, jax.random.normal(jax.random.PRNGKey(2), (d_model, d_model)))

        # Attention scores
        scores = jnp.einsum('bqd,bkd->bqk', q, k) / jnp.sqrt(d_model)
        attn = jax.nn.softmax(scores, axis=-1)

        # Output
        v = jnp.dot(x, jax.random.normal(jax.random.PRNGKey(3), (d_model, d_model)))
        out = jnp.einsum('bqk,bvd->bqd', attn, v)

        return jnp.mean(out ** 2)

    for batch_size in batch_sizes:
        try:
            # JIT compile
            jitted_fn = jax.jit(lambda: dummy_forward(batch_size))

            # Warmup
            _ = jitted_fn()

            # Benchmark
            times = []
            for _ in range(5):
                start = time.time()
                result = jitted_fn()
                result.block_until_ready()
                times.append(time.time() - start)

            avg_time = sum(times) / len(times)
            tokens_per_sec = (batch_size * seq_length) / avg_time

            print(f"Batch {batch_size:3d}: {avg_time*1000:5.1f}ms | {tokens_per_sec:8.0f} tokens/sec")

        except Exception as e:
            print(f"Batch {batch_size:3d}: ❌ Failed - {str(e)[:40]}...")

def create_optimized_configs():
    """Create training configs with different batch sizes"""

    base_config = {
        'vocab_size': 8000,
        'seq_length': 256,
        'd_model': 512,
        'n_heads': 8,
        'n_layers': 6,
        'd_ff': 2048,
        'dropout_rate': 0.1,
        'T': 16,
        'learning_rate': 1e-4,
        'weight_decay': 1e-2,
        'log_every': 200,
        'eval_every': 2500,
    }

    configs = {}

    # Different batch size configurations
    batch_configs = [
        ('small', 32, 1e-4),      # Current
        ('medium', 64, 1.4e-4),   # √2 scaling
        ('large', 128, 2e-4),     # 2x scaling
        ('xlarge', 256, 2.8e-4),  # 2√2 scaling
        ('xxlarge', 512, 4e-4),   # 4x scaling (if it fits)
    ]

    print("\n🔧 Optimized Training Configurations:")
    print("=" * 60)

    for name, batch_size, lr in batch_configs:
        config = base_config.copy()
        config['batch_size'] = batch_size
        config['learning_rate'] = lr

        memory_gb = estimate_memory_usage(batch_size) / 1024
        configs[name] = config

        print(f"{name:8s}: batch={batch_size:3d}, lr={lr:.1e}, memory~{memory_gb:.1f}GB")

    return configs

def train_with_optimal_batch_size(config_name='large'):
    """Train with optimized batch size"""

    configs = create_optimized_configs()

    if config_name not in configs:
        print(f"❌ Config '{config_name}' not found. Available: {list(configs.keys())}")
        return

    config_dict = configs[config_name]
    batch_size = config_dict['batch_size']
    memory_gb = estimate_memory_usage(batch_size) / 1024

    print(f"\n🚀 Training with '{config_name}' configuration:")
    print(f"   Batch size: {batch_size}")
    print(f"   Learning rate: {config_dict['learning_rate']}")
    print(f"   Estimated memory: {memory_gb:.1f}GB")

    # Create D3PM config with the correct settings
    config = D3PMConfig(**config_dict)

    # Warning for large batch sizes
    if batch_size >= 256:
        print(f"⚠️  Large batch size detected!")
        print(f"   - May need learning rate warmup")
        print(f"   - Watch for training instability")
        print(f"   - Consider gradient clipping")

    # Setup data (reuse existing if available)
    try:
        # Check if we already have tokenizer and datasets
        if 'tokenizer' in globals() and 'train_dataset' in globals():
            print("♻️  Reusing existing tokenizer and datasets...")
            global tokenizer, train_dataset, val_dataset
        else:
            raise NameError("Need to setup data")
    except:
        print("🔧 Setting up real TinyStories training...")
        print("Setting up real TinyStories dataset...")
        tokenizer = SentencePieceTokenizer(vocab_size=config.vocab_size)
        tokenizer.train_tokenizer(num_samples=20000)
        config.vocab_size = tokenizer.sp.vocab_size()

        train_dataset = RealTinyStoriesDataset(tokenizer, config.seq_length, "train")
        val_dataset = RealTinyStoriesDataset(tokenizer, config.seq_length, "validation")

        print(f"✅ Real data setup complete!")
        print(f"   Vocabulary size: {config.vocab_size}")
        print(f"   Mask token ID: {tokenizer.mask_id}")

        # Test the dataset
        print("\n📖 Sample from real dataset:")
        sample_batch = next(iter(train_dataset))
        decoded_sample = tokenizer.decode(sample_batch.tolist())
        clean_sample = decoded_sample.replace('▁', ' ').strip()
        print(f"Sample text: {clean_sample[:200]}...")

    # Create trainer with the CORRECT config
    trainer = RealDataD3PMTrainer(config, tokenizer, train_dataset, val_dataset)

    # Train the model
    print(f"\n🚀 Training with batch_size={batch_size}, lr={config.learning_rate:.1e}...")
    history = trainer.train_with_monitoring(
        num_epochs=5,
        steps_per_epoch=1000
    )

    # Generate samples
    trainer.generate_samples(num_samples=5)

    # Show training stats
    if history and 'epoch_loss' in history and history['epoch_loss']:
        print(f"\n📈 Training Statistics:")
        print(f"   Initial loss: {history['epoch_loss'][0]:.4f}")
        print(f"   Final loss: {history['epoch_loss'][-1]:.4f}")
        print(f"   Loss reduction: {history['epoch_loss'][0] - history['epoch_loss'][-1]:.4f}")

    return trainer, history

# Batch size comparison function
def compare_batch_sizes():
    """Compare training with different batch sizes"""

    print("🏁 Batch Size Comparison Study")
    print("=" * 50)

    results = {}

    for config_name in ['small', 'medium', 'large']:
        print(f"\n🔄 Testing {config_name} configuration...")

        try:
            trainer, history = train_with_optimal_batch_size(config_name)

            if history and 'epoch_loss' in history:
                final_loss = history['epoch_loss'][-1] if history['epoch_loss'] else float('inf')
                results[config_name] = {
                    'final_loss': final_loss,
                    'success': True
                }
                print(f"✅ {config_name}: Final loss = {final_loss:.4f}")
            else:
                results[config_name] = {'success': False}
                print(f"❌ {config_name}: Failed to train")

        except Exception as e:
            results[config_name] = {'success': False, 'error': str(e)}
            print(f"❌ {config_name}: Error - {str(e)[:50]}...")

    # Summary
    print(f"\n📊 Batch Size Comparison Results:")
    print("=" * 50)

    for config_name, result in results.items():
        if result['success']:
            print(f"{config_name:8s}: ✅ Loss = {result['final_loss']:.4f}")
        else:
            print(f"{config_name:8s}: ❌ Failed")

    return results

# Usage instructions
print("""
🎯 TPU Batch Size Optimization:

1. Check memory estimates:
   find_optimal_batch_size()

2. Benchmark performance:
   benchmark_batch_sizes()

3. See optimized configs:
   create_optimized_configs()

4. Train with larger batch:
   trainer, history = train_with_optimal_batch_size('large')  # batch_size=128

5. Compare multiple batch sizes:
   results = compare_batch_sizes()

💡 Quick recommendations for your setup:
- Current: batch_size=32 (only 4.5% memory usage!)
- Try: batch_size=128 (should use ~15-20% memory)
- Max: batch_size=512+ (if you want to push limits)

⚠️  Remember: Larger batch = higher learning rate needed!
""")

# Run the analysis
find_optimal_batch_size()

"""# 1.5 new setup for real tiny stories and training!!

## 1.5b new Code Explanation

This code sets up the components needed to train the D3PM model on the real TinyStories dataset instead of mock data. 📚

---

## Key Components

* **`RealTinyStoriesDataset` Class**: This class implements an iterator that loads the TinyStories dataset using the `datasets` library. It tokenizes stories and prepares them into fixed-length sequences, allowing the model to process real text data in batches.

* **`SentencePieceTokenizer` Class**: This class handles the real SentencePiece tokenizer.
    * **`train_tokenizer()`**: Downloads a subset of the TinyStories dataset and trains a SentencePiece tokenizer model with a specified vocabulary size.
    * **`encode()`**: Converts raw text into sequences of token IDs.
    * **`decode()`**: Converts sequences of token IDs back into human-readable text.
    * **`mask_id`**: Provides the token ID designated for masking during the diffusion process.

* **`setup_real_data_training()` Function**: This function orchestrates the setup process. It defines a `D3PMConfig`, creates and trains the `SentencePieceTokenizer`, and then creates instances of the `RealTinyStoriesDataset` for both training and validation.

* **`RealDataD3PMTrainer` Class**: This class modifies the `AdvancedD3PMTrainer` to use the real tokenizer and datasets instead of the mock ones.

* **`train_on_real_data()` Function**: This is an example function demonstrating how to set up the real data and then create and run the `RealDataD3PMTrainer`. It also includes a step to generate samples after training.

---

## In Summary

This code replaces the mock data and tokenizer with real-world components. By using the TinyStories dataset and a custom-trained SentencePiece tokenizer, it enables the model to learn from and generate actual human-like text.
"""

# Setup for Real TinyStories Dataset
# This shows how you would use actual text data instead of random tokens

# First, install required packages (run this in a cell):
"""
!pip install datasets transformers sentencepiece
"""

import json
from datasets import load_dataset
import sentencepiece as spm
from pathlib import Path
import tempfile

class RealTinyStoriesDataset:
    """Real TinyStories dataset implementation"""

    def __init__(self, tokenizer, seq_length: int = 256, split: str = "train"):
        self.tokenizer = tokenizer
        self.seq_length = seq_length
        self.split = split

        # Load TinyStories dataset
        print(f"Loading TinyStories dataset ({split} split)...")
        self.dataset = load_dataset("roneneldan/TinyStories", split=split, streaming=True)
        self.iterator = iter(self.dataset)

    def __iter__(self):
        """Generate tokenized sequences from real stories"""
        while True:
            try:
                # Get next story
                story = next(self.iterator)['text']

                # Tokenize the story
                tokens = self.tokenizer.encode(story)

                # Split into chunks if too long, or pad if too short
                if len(tokens) >= self.seq_length:
                    # Take a random chunk
                    start_idx = np.random.randint(0, len(tokens) - self.seq_length + 1)
                    sequence = tokens[start_idx:start_idx + self.seq_length]
                else:
                    # Pad short sequences
                    sequence = tokens + [0] * (self.seq_length - len(tokens))

                yield np.array(sequence, dtype=np.int32)

            except StopIteration:
                # Reset iterator when dataset is exhausted
                self.iterator = iter(self.dataset)

class SentencePieceTokenizer:
    """Real SentencePiece tokenizer for TinyStories"""

    def __init__(self, vocab_size: int = 8000):
        self.vocab_size = vocab_size
        self.model_path = None
        self.sp = None

    def train_tokenizer(self, num_samples: int = 10000):
        """Train tokenizer on TinyStories data"""
        print(f"Training SentencePiece tokenizer (vocab_size={self.vocab_size})...")

        # Get sample data for training tokenizer
        dataset = load_dataset("roneneldan/TinyStories", split="train", streaming=True)

        # Collect text samples
        texts = []
        for i, item in enumerate(dataset):
            if i >= num_samples:
                break
            texts.append(item['text'])

        # Write to temporary file
        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt') as f:
            for text in texts:
                f.write(text + '\n')
            temp_file = f.name

        # Train SentencePiece model
        model_prefix = 'tinystories_tokenizer'
        spm.SentencePieceTrainer.train(
            input=temp_file,
            model_prefix=model_prefix,
            vocab_size=self.vocab_size,
            character_coverage=0.995,
            model_type='bpe',
            pad_id=0,
            unk_id=1,
            bos_id=2,
            eos_id=3,
            user_defined_symbols=['[MASK]']
        )

        # Load the trained model
        self.model_path = f'{model_prefix}.model'
        self.sp = spm.SentencePieceProcessor(model_file=self.model_path)

        # Clean up
        Path(temp_file).unlink()

        print(f"Tokenizer trained! Vocabulary size: {self.sp.vocab_size()}")

        # Test the tokenizer
        test_text = "Once upon a time, there was a little girl who loved to read stories."
        tokens = self.encode(test_text)
        decoded = self.decode(tokens)
        print(f"Test - Original: {test_text}")
        print(f"Test - Tokens: {tokens[:10]}...")
        print(f"Test - Decoded: {decoded}")

    def encode(self, text: str) -> list:
        """Encode text to token IDs"""
        if self.sp is None:
            raise ValueError("Tokenizer not trained yet!")
        return self.sp.encode(text, out_type=int)

    def decode(self, ids: list) -> str:
        """Decode token IDs to text"""
        if self.sp is None:
            raise ValueError("Tokenizer not trained yet!")
        return self.sp.decode([int(id) for id in ids])

    @property
    def mask_id(self):
        """Get mask token ID"""
        if self.sp is None:
            raise ValueError("Tokenizer not trained yet!")
        return self.sp.piece_to_id('[MASK]')

def setup_real_data_training():
    """Setup training with real TinyStories data"""

    # Configuration for real data
    config = D3PMConfig(
        vocab_size=8000,    # Will be set by tokenizer
        seq_length=256,
        d_model=512,
        n_heads=8,
        n_layers=6,
        d_ff=2048,
        dropout_rate=0.1,
        T=16,
        batch_size=32,
        learning_rate=1e-4,
        weight_decay=1e-2,
        max_steps=50_000,
        log_every=500,
        eval_every=2500,
    )

    # Create and train tokenizer
    print("Setting up real TinyStories dataset...")
    tokenizer = SentencePieceTokenizer(vocab_size=config.vocab_size)
    tokenizer.train_tokenizer(num_samples=20000)  # Use 20k samples for tokenizer training

    # Update vocab size to actual tokenizer vocab size
    config.vocab_size = tokenizer.sp.vocab_size()

    # Create datasets
    train_dataset = RealTinyStoriesDataset(tokenizer, config.seq_length, "train")
    val_dataset = RealTinyStoriesDataset(tokenizer, config.seq_length, "validation")

    print(f"✅ Real data setup complete!")
    print(f"   Vocabulary size: {config.vocab_size}")
    print(f"   Mask token ID: {tokenizer.mask_id}")

    # Test the dataset
    print("\n📖 Sample from real dataset:")
    sample_batch = next(iter(train_dataset))
    decoded_sample = tokenizer.decode(sample_batch.tolist())
    print(f"Sample text: {decoded_sample[:200]}...")

    return config, tokenizer, train_dataset, val_dataset

# Modified trainer for real data
class RealDataD3PMTrainer(AdvancedD3PMTrainer):
    """D3PM trainer that works with real TinyStories data"""

    def __init__(self, config, tokenizer, train_dataset, val_dataset):
        # Initialize without calling parent __init__ to avoid mock data setup
        self.config = config
        self.use_mock_data = False

        # Use real tokenizer and datasets
        self.tokenizer = tokenizer
        self.train_dataset = train_dataset
        self.val_dataset = val_dataset

        # Initialize model
        self.model = D3PMDenoiser(config=config)
        self.mask_id = tokenizer.mask_id

        # Diffusion schedule
        self.betas = jnp.linspace(config.beta_start, config.beta_end, config.T)

        # Initialize training state
        self.step = 0
        self.params = None
        self.opt_state = None

        # Training history
        from collections import defaultdict
        self.training_history = defaultdict(list)
        self.best_loss = float('inf')

    def get_data_loader(self, dataset=None):
        """Get batched data loader for real data"""
        if dataset is None:
            dataset = self.train_dataset

        def batch_generator():
            batch = []
            for item in dataset:
                batch.append(item)
                if len(batch) == self.config.batch_size:
                    yield jnp.array(batch)
                    batch = []

        return batch_generator()

# Example usage function
def train_on_real_data():
    """Train D3PM on real TinyStories data"""

    print("🔧 Setting up real TinyStories training...")

    # Setup real data
    config, tokenizer, train_dataset, val_dataset = setup_real_data_training()

    # Create trainer with real data
    trainer = RealDataD3PMTrainer(config, tokenizer, train_dataset, val_dataset)

    print("\n🚀 Training on real TinyStories data...")

    # Train the model
    history = trainer.train_with_monitoring(
        num_epochs=5,
        steps_per_epoch=2000  # More steps since we have real data
    )

    # Generate samples
    print("\n🎭 Generating samples from real data training:")
    trainer.generate_samples(num_samples=5)

    return trainer, history

# Instructions for use:
print("""
🗂️ Current Training Data: RANDOM MOCK DATA
   - Just random token sequences
   - No real language patterns
   - Output: "word_123 word_456 word_789..."

📚 To train on REAL TinyStories data:
   1. Run: !pip install datasets transformers sentencepiece
   2. Run: train_on_real_data()

   This will:
   - Download TinyStories dataset (children's stories)
   - Train a proper tokenizer on real text
   - Train D3PM to generate actual stories!

🎯 Real TinyStories contains:
   - Simple children's stories
   - ~2M stories, each 1-5 sentences
   - Generated by GPT-3.5/4 for research
   - Perfect for training language models
""")

train_on_real_data()

"""## 1.6 TRAINING CODE WITH OPTIMIZER WARMUP SCHEDULE

**TRAINING WITH XXL BATCH SIZE, 60% of TPU V6E MEMORY APPROX.**
```
  trainer, history = train_with_warmup_config('xxlarge', warmup_ratio=0.2)  # batch=512, 20% warmup

```

## 1.6b Code Explanation

This code introduces learning rate warmup and advanced scheduling for the D3PM trainer. 📈

---

## Key Components

* **`create_warmup_schedule`**: This function generates a learning rate schedule. The schedule starts at a low value, increases to a peak learning rate during a "warmup" phase, and then optionally decays according to different patterns like **cosine**, **linear**, **exponential**, or remains **constant**.

* **`plot_lr_schedule`**: A utility function to visualize the created learning rate schedule, showing how the learning rate changes over the course of training steps.

* **`WarmupD3PMTrainer`**: This class inherits from `RealDataD3PMTrainer` and incorporates the learning rate schedule. Its features include:
    * **Initialization (`init_training`)**: Sets up the optimizer with the defined learning rate schedule.
    * **Gradient Clipping**: An option (`use_gradient_clipping`) to help with training stability, which is especially useful with larger batch sizes.
    * **Modified Training Step (`train_step_with_warmup`)**: Implicitly uses the learning rate from the schedule based on the current step number.
    * **Enhanced Training Loop (`train_with_warmup`)**: Tracks and logs the current learning rate during training and plots the learning rate history afterward.

* **`train_with_warmup_config`**: This function orchestrates a training run using the `WarmupD3PMTrainer`. It takes a configuration name (e.g., 'xlarge'), a warmup ratio, and types for the warmup and decay phases. It sets up the data, creates the trainer with the specified parameters, and starts the training process.

---

## In Essence

This code provides a flexible way to manage the learning rate during training. This control is crucial for optimizing model performance and ensuring stability, particularly when using techniques like large-batch training.
"""

# D3PM Training with Learning Rate Warmup and Advanced Scheduling

import jax
import jax.numpy as jnp
import optax
import time
import matplotlib.pyplot as plt
import numpy as np
from typing import Optional, Dict, Any

def create_warmup_schedule(peak_lr: float, warmup_steps: int, total_steps: int,
                          warmup_type: str = "linear", decay_type: str = "cosine"):
    """
    Create learning rate schedule with warmup

    Args:
        peak_lr: Peak learning rate after warmup
        warmup_steps: Number of warmup steps
        total_steps: Total training steps
        warmup_type: "linear", "exponential", or "cosine"
        decay_type: "cosine", "linear", "constant", or "exponential"
    """

    def warmup_fn(step):
        if warmup_type == "linear":
            return peak_lr * step / warmup_steps
        elif warmup_type == "exponential":
            return peak_lr * (step / warmup_steps) ** 2
        elif warmup_type == "cosine":
            return peak_lr * 0.5 * (1 + jnp.cos(jnp.pi * (1 - step / warmup_steps)))
        else:
            return peak_lr * step / warmup_steps  # Default to linear

    def decay_fn(step):
        progress = (step - warmup_steps) / (total_steps - warmup_steps)
        if decay_type == "cosine":
            return peak_lr * 0.5 * (1 + jnp.cos(jnp.pi * progress))
        elif decay_type == "linear":
            return peak_lr * (1 - progress)
        elif decay_type == "exponential":
            return peak_lr * (0.1 ** progress)
        else:  # constant
            return peak_lr

    def schedule(step):
        return jnp.where(
            step < warmup_steps,
            warmup_fn(step),
            decay_fn(step)
        )

    return schedule

def plot_lr_schedule(schedule_fn, total_steps: int, warmup_steps: int, title: str = "Learning Rate Schedule"):
    """Plot the learning rate schedule"""
    steps = np.arange(0, total_steps)
    lrs = [float(schedule_fn(step)) for step in steps]

    plt.figure(figsize=(10, 6))
    plt.plot(steps, lrs, 'b-', linewidth=2)
    plt.axvline(x=warmup_steps, color='r', linestyle='--', alpha=0.7, label=f'Warmup ends ({warmup_steps} steps)')
    plt.xlabel('Training Step')
    plt.ylabel('Learning Rate')
    plt.title(title)
    plt.grid(True, alpha=0.3)
    plt.legend()
    plt.show()

    print(f"📊 Learning Rate Schedule:")
    print(f"   Initial LR: {lrs[0]:.2e}")
    print(f"   Peak LR: {max(lrs):.2e}")
    print(f"   Final LR: {lrs[-1]:.2e}")
    print(f"   Warmup steps: {warmup_steps}")

class WarmupD3PMTrainer(RealDataD3PMTrainer):
    """D3PM trainer with learning rate warmup and advanced scheduling"""

    def __init__(self, config, tokenizer, train_dataset, val_dataset,
                 warmup_steps: int = 1000, warmup_type: str = "linear",
                 decay_type: str = "cosine", use_gradient_clipping: bool = True):
        super().__init__(config, tokenizer, train_dataset, val_dataset)

        self.warmup_steps = warmup_steps
        self.warmup_type = warmup_type
        self.decay_type = decay_type
        self.use_gradient_clipping = use_gradient_clipping
        self.current_lr = 0.0

        print(f"🔥 Warmup Training Configuration:")
        print(f"   Peak learning rate: {config.learning_rate:.2e}")
        print(f"   Warmup steps: {warmup_steps}")
        print(f"   Warmup type: {warmup_type}")
        print(f"   Decay type: {decay_type}")
        print(f"   Gradient clipping: {use_gradient_clipping}")

    def init_training(self, key, total_steps: int):
        """Initialize training with warmup schedule"""
        # Initialize parameters
        dummy_batch = jnp.ones((1, self.config.seq_length), dtype=jnp.int32)
        dummy_t = jnp.zeros((1,), dtype=jnp.int32)

        variables = self.model.init(
            key,
            dummy_batch,
            dummy_t,
            deterministic=True
        )
        self.params = variables['params']

        # Create learning rate schedule
        self.lr_schedule = create_warmup_schedule(
            peak_lr=self.config.learning_rate,
            warmup_steps=self.warmup_steps,
            total_steps=total_steps,
            warmup_type=self.warmup_type,
            decay_type=self.decay_type
        )

        # Create optimizer with scheduling
        base_optimizer = optax.adamw(
            learning_rate=self.lr_schedule,
            b1=0.9, b2=0.95,
            weight_decay=self.config.weight_decay
        )

        # Add gradient clipping if enabled
        if self.use_gradient_clipping:
            self.tx = optax.chain(
                optax.clip_by_global_norm(1.0),  # Clip gradients
                base_optimizer
            )
            print("✂️  Gradient clipping enabled (max_norm=1.0)")
        else:
            self.tx = base_optimizer

        self.opt_state = self.tx.init(self.params)

        print(f"✅ Model initialized with warmup schedule ({self._count_params()/1e6:.1f}M parameters)")

        # Plot the learning rate schedule
        plot_lr_schedule(self.lr_schedule, total_steps, self.warmup_steps,
                        f"LR Schedule: {self.warmup_type} warmup + {self.decay_type} decay")

    @functools.partial(jax.jit, static_argnums=(0, 6))
    def train_step_with_warmup(self, params, opt_state, batch, rng, step, deterministic=False):
        """Training step with warmup - step is used for LR scheduling"""
        # The learning rate is automatically handled by the schedule in the optimizer
        loss, grads = jax.value_and_grad(self.loss_fn)(params, batch, rng, deterministic)
        updates, new_opt_state = self.tx.update(grads, opt_state, params)
        new_params = optax.apply_updates(params, updates)

        # Get current learning rate for monitoring
        current_lr = self.lr_schedule(step)

        return new_params, new_opt_state, loss, current_lr

    def train_with_warmup(self, num_epochs: int = 5, steps_per_epoch: int = 1000):
        """Train with warmup and advanced monitoring"""
        total_steps = num_epochs * steps_per_epoch

        if self.params is None:
            self.init_training(jax.random.PRNGKey(42), total_steps)

        data_loader = self.get_data_loader()

        print(f"\n🚀 Starting Warmup Training")
        print(f"📊 Model: {self._count_params()/1e6:.1f}M parameters")
        print(f"🎯 Training for {num_epochs} epochs ({steps_per_epoch} steps each)")
        print(f"📈 Total steps: {total_steps:,}")
        print(f"💾 Batch size: {self.config.batch_size}")
        print("=" * 60)

        start_time = time.time()
        step = 0
        lr_history = []

        try:
            for epoch in range(num_epochs):
                epoch_start = time.time()
                epoch_losses = []
                epoch_lrs = []

                print(f"\n📅 Epoch {epoch + 1}/{num_epochs}")

                for step_in_epoch in range(steps_per_epoch):
                    # Get batch
                    try:
                        batch = next(data_loader)
                    except StopIteration:
                        data_loader = self.get_data_loader()
                        batch = next(data_loader)

                    # Training step with warmup
                    rng = jax.random.fold_in(jax.random.PRNGKey(42), step)
                    self.params, self.opt_state, loss, current_lr = self.train_step_with_warmup(
                        self.params, self.opt_state, batch, rng, step, False
                    )

                    epoch_losses.append(float(loss))
                    epoch_lrs.append(float(current_lr))
                    lr_history.append(float(current_lr))
                    step += 1

                    # Progress indicator
                    if step_in_epoch % 50 == 0:
                        progress = step_in_epoch / steps_per_epoch * 100
                        print(f"\r    Progress: {progress:5.1f}% | LR: {current_lr:.2e}", end="")

                    # Detailed logging
                    if step % self.config.log_every == 0:
                        elapsed = time.time() - start_time
                        tokens_per_sec = step * self.config.batch_size * self.config.seq_length / elapsed
                        avg_loss = np.mean(epoch_losses[-50:]) if epoch_losses else loss

                        warmup_status = "🔥 Warmup" if step < self.warmup_steps else "🚀 Training"

                        print(f"\n  Step {step:5d} | Loss: {avg_loss:.4f} | "
                              f"LR: {current_lr:.2e} | Tokens/sec: {tokens_per_sec:8.0f} | {warmup_status}")

                    # Evaluation
                    if step % self.config.eval_every == 0 and step > 0:
                        eval_loss = self._quick_eval()
                        self.training_history['eval_loss'].append(eval_loss)
                        self.training_history['eval_steps'].append(step)

                        if eval_loss < self.best_loss:
                            self.best_loss = eval_loss
                            print(f"  🎉 New best validation loss: {eval_loss:.4f}")

                # Epoch summary
                epoch_time = time.time() - epoch_start
                avg_epoch_loss = np.mean(epoch_losses)
                avg_epoch_lr = np.mean(epoch_lrs)

                self.training_history['epoch_loss'].append(avg_epoch_loss)
                self.training_history['epoch_lr'].append(avg_epoch_lr)
                self.training_history['epoch_time'].append(epoch_time)

                print(f"\n✅ Epoch {epoch + 1} completed:")
                print(f"   Average Loss: {avg_epoch_loss:.4f}")
                print(f"   Average LR: {avg_epoch_lr:.2e}")
                print(f"   Time: {epoch_time/60:.1f} minutes")

                # Show warmup progress
                if step < self.warmup_steps:
                    warmup_progress = step / self.warmup_steps * 100
                    print(f"   🔥 Warmup progress: {warmup_progress:.1f}%")
                elif step - steps_per_epoch < self.warmup_steps <= step:
                    print(f"   🚀 Warmup completed this epoch!")

        except KeyboardInterrupt:
            print("\n⏹️  Training interrupted by user")

        total_time = time.time() - start_time

        # Final summary
        print(f"\n🏁 Warmup Training completed!")
        print(f"   Total time: {total_time/60:.1f} minutes")
        print(f"   Warmup completed at step {self.warmup_steps}")
        print(f"   Peak learning rate: {max(lr_history):.2e}")
        print(f"   Final learning rate: {lr_history[-1]:.2e}")

        if epoch_losses:
            print(f"   Final loss: {epoch_losses[-1]:.4f}")
            print(f"   Best validation loss: {self.best_loss:.4f}")

        # Plot learning rate history
        self.plot_training_history(lr_history)

        return self.training_history

    def plot_training_history(self, lr_history):
        """Plot training history including learning rate"""
        if not self.training_history['epoch_loss']:
            print("No training history to plot")
            return

        fig, axes = plt.subplots(2, 2, figsize=(15, 10))

        # Training loss
        epochs = list(range(1, len(self.training_history['epoch_loss']) + 1))
        axes[0, 0].plot(epochs, self.training_history['epoch_loss'], 'b-', linewidth=2)
        axes[0, 0].set_title('Training Loss per Epoch')
        axes[0, 0].set_xlabel('Epoch')
        axes[0, 0].set_ylabel('Loss')
        axes[0, 0].grid(True, alpha=0.3)

        # Learning rate over time
        steps = list(range(len(lr_history)))
        axes[0, 1].plot(steps, lr_history, 'r-', linewidth=2)
        axes[0, 1].axvline(x=self.warmup_steps, color='orange', linestyle='--',
                          alpha=0.7, label=f'Warmup ends')
        axes[0, 1].set_title('Learning Rate Schedule')
        axes[0, 1].set_xlabel('Step')
        axes[0, 1].set_ylabel('Learning Rate')
        axes[0, 1].set_yscale('log')
        axes[0, 1].grid(True, alpha=0.3)
        axes[0, 1].legend()

        # Validation loss
        if self.training_history['eval_loss']:
            axes[1, 0].plot(self.training_history['eval_steps'],
                           self.training_history['eval_loss'], 'g-', linewidth=2)
            axes[1, 0].set_title('Validation Loss')
            axes[1, 0].set_xlabel('Step')
            axes[1, 0].set_ylabel('Validation Loss')
            axes[1, 0].grid(True, alpha=0.3)

        # Training time per epoch
        if self.training_history['epoch_time']:
            axes[1, 1].plot(epochs, self.training_history['epoch_time'], 'purple', linewidth=2)
            axes[1, 1].set_title('Training Time per Epoch')
            axes[1, 1].set_xlabel('Epoch')
            axes[1, 1].set_ylabel('Time (seconds)')
            axes[1, 1].grid(True, alpha=0.3)

        plt.tight_layout()
        plt.show()

def train_with_warmup_config(config_name='xlarge', warmup_ratio=0.1, warmup_type="linear",
                           decay_type="cosine", use_gradient_clipping=True,
                           num_epochs=5, steps_per_epoch=1000):
    """
    Train with warmup using predefined configurations

    Args:
        config_name: 'medium', 'large', 'xlarge', 'xxlarge'
        warmup_ratio: Fraction of training for warmup (e.g., 0.1 = 10%)
        warmup_type: 'linear', 'exponential', 'cosine'
        decay_type: 'cosine', 'linear', 'constant', 'exponential'
        use_gradient_clipping: Whether to clip gradients
        num_epochs: Number of training epochs
        steps_per_epoch: Steps per epoch
    """

    # Get configuration
    configs = create_optimized_configs()

    if config_name not in configs:
        print(f"❌ Config '{config_name}' not found. Available: {list(configs.keys())}")
        return None, None

    config_dict = configs[config_name]
    batch_size = config_dict['batch_size']
    total_steps = num_epochs * steps_per_epoch
    warmup_steps = int(total_steps * warmup_ratio)

    print(f"🔥 Warmup Training Setup:")
    print(f"   Configuration: {config_name}")
    print(f"   Batch size: {batch_size}")
    print(f"   Peak learning rate: {config_dict['learning_rate']:.2e}")
    print(f"   Total steps: {total_steps:,}")
    print(f"   Warmup steps: {warmup_steps:,} ({warmup_ratio*100:.1f}%)")
    print(f"   Warmup type: {warmup_type}")
    print(f"   Decay type: {decay_type}")

    # Create config
    config = D3PMConfig(**config_dict)

    # Setup data (reuse existing if available)
    try:
        if 'tokenizer' in globals() and 'train_dataset' in globals():
            print("♻️  Reusing existing tokenizer and datasets...")
            global tokenizer, train_dataset, val_dataset
        else:
            raise NameError("Need to setup data")
    except:
        print("🔧 Setting up real TinyStories training...")
        tokenizer = SentencePieceTokenizer(vocab_size=config.vocab_size)
        tokenizer.train_tokenizer(num_samples=20000)
        config.vocab_size = tokenizer.sp.vocab_size()

        train_dataset = RealTinyStoriesDataset(tokenizer, config.seq_length, "train")
        val_dataset = RealTinyStoriesDataset(tokenizer, config.seq_length, "validation")

    # Create warmup trainer
    trainer = WarmupD3PMTrainer(
        config, tokenizer, train_dataset, val_dataset,
        warmup_steps=warmup_steps,
        warmup_type=warmup_type,
        decay_type=decay_type,
        use_gradient_clipping=use_gradient_clipping
    )

    # Train with warmup
    history = trainer.train_with_warmup(
        num_epochs=num_epochs,
        steps_per_epoch=steps_per_epoch
    )

    # Generate samples
    trainer.generate_samples(num_samples=5)

    return trainer, history

# Usage examples
print("""
🔥 Learning Rate Warmup Training Options:

1. RECOMMENDED - Large batch with warmup:
   trainer, history = train_with_warmup_config('xlarge')  # batch=256, 10% warmup

2. AGGRESSIVE - Very large batch with longer warmup:
   trainer, history = train_with_warmup_config('xxlarge', warmup_ratio=0.2)  # batch=512, 20% warmup

3. CUSTOM WARMUP SCHEDULE:
   trainer, history = train_with_warmup_config(
       config_name='xlarge',
       warmup_ratio=0.15,      # 15% warmup
       warmup_type='cosine',   # Cosine warmup
       decay_type='linear',    # Linear decay
       use_gradient_clipping=True
   )

📊 Recommended Settings by Batch Size:
   Batch 128: warmup_ratio=0.05 (5% warmup)
   Batch 256: warmup_ratio=0.10 (10% warmup)  ← Recommended
   Batch 512: warmup_ratio=0.15 (15% warmup)
   Batch 1024: warmup_ratio=0.20 (20% warmup)

🎯 Why Warmup Helps Large Batches:
   - Prevents early training instability
   - Allows model to "settle" before full LR
   - Better convergence with large gradient steps
   - Reduces risk of divergence
""")

trainer, history = train_with_warmup_config('xlarge')  # batch=256, 10% warmup

"""## 1.7 TRAINING CODE WITH SMOKE TESTING

```python
#🧪 COMPREHENSIVE SMOKE TESTING SYSTEM

#Features:
#✅ JSON serialization testing (all data types)
#✅ File I/O testing (actual checkpoint writing)
#✅ Mini training run (10 steps + validation + checkpoint)
#✅ JAX/NumPy type conversion testing
#✅ Full pipeline validation

#Usage:
#1. FULL SMOKE TEST (recommended):
trainer, metrics = run_smoke_tested_experiment('xlarge', num_epochs=30)

#2. SKIP SMOKE TEST (if you're confident):
trainer, metrics = run_smoke_tested_experiment('xlarge', num_epochs=30, run_smoke_test=False)

#3. SMOKE TEST ONLY (for debugging):
trainer = SmokeTestableResearchTrainer(config, tokenizer, train_dataset, val_dataset)
trainer.comprehensive_smoke_test()

#The smoke test takes ~1-2 minutes but can save hours of wasted training!
```

## 1.7b Code Explanation

This code defines the **`SmokeTestableResearchTrainer`** class, which extends the `WarmupD3PMTrainer` to include a comprehensive smoke testing system and enhanced research-grade training features. ✅

---

## Key Components

* **`SmokeTestableResearchTrainer` Class**: This class inherits from `WarmupD3PMTrainer` and adds functionalities for:
    * **Checkpointing Setup**: Configures a directory for saving model checkpoints and tracks metrics like losses, learning rates, and best validation performance.
    * **`smoke_test_json_serialization()`**: A method to test that various data types (including JAX and NumPy arrays) can be correctly serialized to JSON, including writing and reading files.
    * **`run_mini_training_test()`**: Executes a few training and validation steps, then tests the checkpoint saving and loading mechanisms to verify the end-to-end pipeline.
    * **`comprehensive_smoke_test()`**: Runs both the JSON serialization and mini-training tests to catch potential issues before a full training job.
    * **`save_checkpoint()`**: Saves the model's state to a pickle file and metadata to a JSON file. It also handles saving a separate 'best' checkpoint based on validation loss.
    * **`load_checkpoint()`**: Loads a previously saved checkpoint to resume training.
    * **`research_training_loop()`**: The main training loop for research experiments, which can optionally run the smoke test before starting. It includes periodic evaluation, checkpointing, and detailed metric tracking.

* **`run_smoke_tested_experiment()`**: This function is the entry point for running a full research experiment. It sets up the configuration, tokenizer, and datasets, creates the trainer, and starts the `research_training_loop`. It allows for specifying the configuration, epochs, experiment name, and whether to run the smoke test.

---

## In Essence

This code provides a robust framework for running machine learning research experiments. It emphasizes upfront testing to ensure the training pipeline is functional and incorporates features for tracking detailed metrics and saving model checkpoints. **🔬**
"""

# Research-Grade D3PM Training with Comprehensive Smoke Testing

import jax
import jax.numpy as jnp
import pickle
import json
from pathlib import Path
import time
import numpy as np
from typing import Dict, Any, Optional
import matplotlib.pyplot as plt

def make_json_serializable(obj):
    """Convert JAX/NumPy types to JSON-serializable Python types"""
    if isinstance(obj, dict):
        return {key: make_json_serializable(value) for key, value in obj.items()}
    elif isinstance(obj, (list, tuple)):
        return [make_json_serializable(item) for item in obj]
    elif isinstance(obj, (np.ndarray, jnp.ndarray)):
        return obj.tolist()
    elif isinstance(obj, (np.integer, jnp.integer)):
        return int(obj)
    elif isinstance(obj, (np.floating, jnp.floating)):
        return float(obj)
    elif isinstance(obj, (np.bool_, jnp.bool_)):
        return bool(obj)
    elif hasattr(obj, 'item'):  # JAX/NumPy scalar
        return obj.item()
    else:
        return obj

class SmokeTestableResearchTrainer(WarmupD3PMTrainer):
    """Research-grade trainer with comprehensive upfront smoke testing"""

    def __init__(self, config, tokenizer, train_dataset, val_dataset,
                 warmup_steps: int = 1000, warmup_type: str = "linear",
                 decay_type: str = "cosine", use_gradient_clipping: bool = True,
                 checkpoint_dir: str = "checkpoints", experiment_name: str = "d3pm_tinystories"):

        super().__init__(config, tokenizer, train_dataset, val_dataset,
                         warmup_steps, warmup_type, decay_type, use_gradient_clipping)

        # Checkpointing setup
        self.checkpoint_dir = Path(checkpoint_dir)
        self.experiment_name = experiment_name
        self.checkpoint_dir.mkdir(exist_ok=True)

        # Research tracking
        self.training_metrics = {
            'step_losses': [],
            'step_lrs': [],
            'validation_losses': [],
            'validation_steps': [],
            'generation_samples': {},
            'training_time': 0,
            'best_val_loss': float('inf'),
            'best_checkpoint': None
        }

        print(f"🔬 Research-Grade Training Setup:")
        print(f"   Experiment: {experiment_name}")
        print(f"   Checkpoint dir: {checkpoint_dir}")
        print(f"   Advanced evaluation enabled")

    def smoke_test_json_serialization(self) -> bool:
        """Comprehensive smoke test for JSON serialization"""

        print("\n🧪 RUNNING JSON SERIALIZATION SMOKE TEST")
        print("=" * 50)

        test_passed = True
        test_results = {}

        try:
            # Test 1: Basic config serialization
            print("1️⃣  Testing config serialization...")
            config_dict = make_json_serializable(self.config.__dict__)
            json_str = json.dumps(config_dict, indent=2)
            test_results['config'] = "✅ PASS"
            print("   ✅ Config serialization: PASS")

        except Exception as e:
            test_results['config'] = f"❌ FAIL: {e}"
            test_passed = False
            print(f"   ❌ Config serialization: FAIL - {e}")

        try:
            # Test 2: Sample training metrics
            print("2️⃣  Testing training metrics serialization...")
            sample_metrics = {
                'step_losses': [4.5, 3.2, 2.1],
                'step_lrs': [1e-4, 2e-4, 3e-4],
                'validation_losses': [5.2, 4.1],
                'validation_steps': [1000, 2000],
                'training_time': 123.45,
                'best_val_loss': 3.14159,
                'best_checkpoint': 2000
            }
            serializable_metrics = make_json_serializable(sample_metrics)
            json_str = json.dumps(serializable_metrics, indent=2)
            test_results['metrics'] = "✅ PASS"
            print("   ✅ Training metrics serialization: PASS")

        except Exception as e:
            test_results['metrics'] = f"❌ FAIL: {e}"
            test_passed = False
            print(f"   ❌ Training metrics serialization: FAIL - {e}")

        try:
            # Test 3: JAX/NumPy type conversion
            print("3️⃣  Testing JAX/NumPy type conversion...")
            jax_data = {
                'jax_bool': jnp.bool_(True),
                'jax_int': jnp.int32(42),
                'jax_float': jnp.float32(3.14),
                'jax_array': jnp.array([1, 2, 3]),
                'numpy_bool': np.bool_(False),
                'numpy_int': np.int64(123),
                'numpy_float': np.float64(2.718),
                'numpy_array': np.array([4, 5, 6])
            }
            converted_data = make_json_serializable(jax_data)
            json_str = json.dumps(converted_data, indent=2)
            test_results['jax_numpy'] = "✅ PASS"
            print("   ✅ JAX/NumPy type conversion: PASS")

        except Exception as e:
            test_results['jax_numpy'] = f"❌ FAIL: {e}"
            test_passed = False
            print(f"   ❌ JAX/NumPy type conversion: FAIL - {e}")

        try:
            # Test 4: Sample metadata structure
            print("4️⃣  Testing checkpoint metadata structure...")
            sample_metadata = {
                'step': jnp.int32(1000),
                'epoch': jnp.int32(5),
                'loss': jnp.float32(2.5),
                'val_loss': jnp.float32(3.1),
                'timestamp': time.time(),
                'is_best': jnp.bool_(True)
            }
            converted_metadata = make_json_serializable(sample_metadata)
            json_str = json.dumps(converted_metadata, indent=2)
            test_results['metadata'] = "✅ PASS"
            print("   ✅ Checkpoint metadata structure: PASS")

        except Exception as e:
            test_results['metadata'] = f"❌ FAIL: {e}"
            test_passed = False
            print(f"   ❌ Checkpoint metadata structure: FAIL - {e}")

        # Test 5: Write actual test files
        print("5️⃣  Testing actual file writing...")
        test_dir = self.checkpoint_dir / "smoke_test"
        test_dir.mkdir(exist_ok=True)

        try:
            # Test JSON file writing
            test_json_path = test_dir / "test_metadata.json"
            test_data = {
                'test_int': 42,
                'test_float': 3.14,
                'test_bool': True,
                'test_list': [1, 2, 3],
                'test_dict': {'nested': 'value'}
            }
            with open(test_json_path, 'w') as f:
                json.dump(test_data, f, indent=2)

            # Verify we can read it back
            with open(test_json_path, 'r') as f:
                loaded_data = json.load(f)

            test_results['file_io'] = "✅ PASS"
            print("   ✅ File I/O operations: PASS")

        except Exception as e:
            test_results['file_io'] = f"❌ FAIL: {e}"
            test_passed = False
            print(f"   ❌ File I/O operations: FAIL - {e}")

        # Summary
        print("\n📋 SMOKE TEST SUMMARY:")
        print("=" * 30)
        for test_name, result in test_results.items():
            print(f"   {test_name:15}: {result}")

        if test_passed:
            print("\n🎉 ALL SMOKE TESTS PASSED!")
            print("✅ JSON serialization is working correctly")
            print("✅ Ready to proceed with training")
        else:
            print("\n🚨 SMOKE TESTS FAILED!")
            print("❌ Issues detected with JSON serialization")
            print("❌ Fix these issues before starting training")

        # Cleanup test files
        if test_dir.exists():
            import shutil
            shutil.rmtree(test_dir)

        return test_passed

    def run_mini_training_test(self, test_steps: int = 10) -> bool:
        """Run a few training steps to test the full pipeline"""

        print(f"\n🏃 RUNNING MINI TRAINING TEST ({test_steps} steps)")
        print("=" * 50)

        try:
            # Initialize if needed
            if self.params is None:
                self.init_training(jax.random.PRNGKey(42), test_steps * 10)

            data_loader = self.get_data_loader()

            print("1️⃣  Testing training step...")
            for step in range(test_steps):
                # Get batch
                try:
                    batch = next(data_loader)
                except StopIteration:
                    data_loader = self.get_data_loader()
                    batch = next(data_loader)

                # Training step
                rng = jax.random.fold_in(jax.random.PRNGKey(42), step)
                self.params, self.opt_state, loss, current_lr = self.train_step_with_warmup(
                    self.params, self.opt_state, batch, rng, step, False
                )

                # Track metrics
                self.training_metrics['step_losses'].append(float(loss))
                self.training_metrics['step_lrs'].append(float(current_lr))

                if step % 5 == 0:
                    print(f"   Step {step}: Loss={loss:.4f}, LR={current_lr:.2e}")

            print("   ✅ Training steps completed successfully")

            # Test validation
            print("2️⃣  Testing validation...")
            val_loss = self._quick_eval(num_batches=2)
            val_loss_float = float(val_loss)
            self.training_metrics['validation_losses'].append(val_loss_float)
            self.training_metrics['validation_steps'].append(test_steps)
            print(f"   ✅ Validation loss: {val_loss_float:.4f}")

            # Test checkpoint saving
            print("3️⃣  Testing checkpoint saving...")
            checkpoint_path = self.save_checkpoint(test_steps, 1, is_best=True)
            print(f"   ✅ Checkpoint saved: {checkpoint_path.name}")

            # Test checkpoint loading
            print("4️⃣  Testing checkpoint loading...")
            loaded_step, loaded_epoch = self.load_checkpoint(checkpoint_path)
            print(f"   ✅ Checkpoint loaded: step={loaded_step}, epoch={loaded_epoch}")

            print("\n🎉 MINI TRAINING TEST PASSED!")
            print("✅ Full training pipeline is working correctly")
            return True

        except Exception as e:
            print(f"\n🚨 MINI TRAINING TEST FAILED!")
            print(f"❌ Error: {e}")
            import traceback
            traceback.print_exc()
            return False

    def comprehensive_smoke_test(self, run_mini_training: bool = True) -> bool:
        """Run all smoke tests before training"""

        print("🔬 COMPREHENSIVE SMOKE TEST SUITE")
        print("=" * 60)

        # Test 1: JSON serialization
        json_test_passed = self.smoke_test_json_serialization()

        if not json_test_passed:
            print("\n🛑 JSON serialization tests failed. Aborting.")
            return False

        # Test 2: Mini training (optional)
        if run_mini_training:
            mini_training_passed = self.run_mini_training_test()
            if not mini_training_passed:
                print("\n🛑 Mini training test failed. Aborting.")
                return False

        print("\n🎊 ALL SMOKE TESTS PASSED!")
        print("🚀 Ready for full training run!")
        return True

    def save_checkpoint(self, step: int, epoch: int, is_best: bool = False):
        """Save comprehensive checkpoint with JSON serialization fix"""

        checkpoint_data = {
            'step': step,
            'epoch': epoch,
            'params': self.params,
            'opt_state': self.opt_state,
            'config': self.config.__dict__,
            'training_metrics': self.training_metrics,
            'model_config': {
                'vocab_size': self.config.vocab_size,
                'seq_length': self.config.seq_length,
                'd_model': self.config.d_model,
                'n_heads': self.config.n_heads,
                'n_layers': self.config.n_layers,
                'T': self.config.T
            }
        }

        # Save main checkpoint
        checkpoint_name = f"{self.experiment_name}_step_{step}.pkl"
        checkpoint_path = self.checkpoint_dir / checkpoint_name

        with open(checkpoint_path, 'wb') as f:
            pickle.dump(checkpoint_data, f)

        # Save metadata with JSON serialization fix
        metadata = {
            'step': int(step),
            'epoch': int(epoch),
            'loss': float(self.training_metrics['step_losses'][-1]) if self.training_metrics['step_losses'] else 0.0,
            'val_loss': float(self.training_metrics['validation_losses'][-1]) if self.training_metrics['validation_losses'] else 0.0,
            'timestamp': float(time.time()),
            'is_best': bool(is_best)
        }

        # Make sure all values are JSON serializable
        metadata = make_json_serializable(metadata)

        metadata_path = self.checkpoint_dir / f"{self.experiment_name}_step_{step}_metadata.json"
        with open(metadata_path, 'w') as f:
            json.dump(metadata, f, indent=2)

        # Save best checkpoint separately
        if is_best:
            best_path = self.checkpoint_dir / f"{self.experiment_name}_best.pkl"
            with open(best_path, 'wb') as f:
                pickle.dump(checkpoint_data, f)
            print(f"💾 Saved best checkpoint at step {step}")

        print(f"💾 Checkpoint saved: {checkpoint_name}")

        return checkpoint_path

    def load_checkpoint(self, checkpoint_path: str):
        """Load checkpoint and resume training"""

        with open(checkpoint_path, 'rb') as f:
            checkpoint_data = pickle.load(f)

        self.params = checkpoint_data['params']
        self.opt_state = checkpoint_data['opt_state']
        self.training_metrics = checkpoint_data['training_metrics']

        step = checkpoint_data['step']
        epoch = checkpoint_data['epoch']

        print(f"📂 Loaded checkpoint from step {step}, epoch {epoch}")
        return step, epoch

    def research_training_loop(self, num_epochs: int = 100, steps_per_epoch: int = 2000,
                              save_every: int = 10000, eval_every: int = 2000,
                              eval_generation_every: int = 20000, run_smoke_test: bool = True):
        """Research-grade training loop with upfront smoke testing"""

        # Run smoke tests first
        if run_smoke_test:
            if not self.comprehensive_smoke_test(run_mini_training=True):
                print("🛑 Smoke tests failed. Training aborted.")
                return None

            print(f"\n⏱️  Waiting 5 seconds before starting full training...")
            time.sleep(5)

        total_steps = num_epochs * steps_per_epoch

        if self.params is None:
            self.init_training(jax.random.PRNGKey(42), total_steps)

        data_loader = self.get_data_loader()

        print(f"\n🔬 RESEARCH-GRADE D3PM TRAINING")
        print(f"📊 Model: {self._count_params()/1e6:.1f}M parameters")
        print(f"🎯 Training for {num_epochs} epochs ({steps_per_epoch} steps each)")
        print(f"📈 Total steps: {total_steps:,}")
        print(f"💾 Batch size: {self.config.batch_size}")
        print(f"💾 Save every: {save_every} steps")
        print(f"🧪 Eval every: {eval_every} steps")
        print("=" * 80)

        start_time = time.time()
        step = 0

        try:
            for epoch in range(num_epochs):
                epoch_start = time.time()
                epoch_losses = []
                epoch_lrs = []

                print(f"\n📅 Epoch {epoch + 1}/{num_epochs}")

                for step_in_epoch in range(steps_per_epoch):
                    # Get batch
                    try:
                        batch = next(data_loader)
                    except StopIteration:
                        data_loader = self.get_data_loader()
                        batch = next(data_loader)

                    # Training step
                    rng = jax.random.fold_in(jax.random.PRNGKey(42), step)
                    self.params, self.opt_state, loss, current_lr = self.train_step_with_warmup(
                        self.params, self.opt_state, batch, rng, step, False
                    )

                    # Track metrics - ensure JSON serializable
                    epoch_losses.append(float(loss))
                    epoch_lrs.append(float(current_lr))
                    self.training_metrics['step_losses'].append(float(loss))
                    self.training_metrics['step_lrs'].append(float(current_lr))
                    step += 1

                    # Progress indicator
                    if step_in_epoch % 100 == 0:
                        progress = step_in_epoch / steps_per_epoch * 100
                        print(f"\r    Progress: {progress:5.1f}% | LR: {current_lr:.2e} | Loss: {loss:.4f}", end="")

                    # Validation evaluation
                    if step % eval_every == 0 and step > 0:
                        val_loss = self._quick_eval(num_batches=10)
                        val_loss_float = float(val_loss)
                        self.training_metrics['validation_losses'].append(val_loss_float)
                        self.training_metrics['validation_steps'].append(int(step))

                        is_best = val_loss_float < self.training_metrics['best_val_loss']
                        if is_best:
                            self.training_metrics['best_val_loss'] = val_loss_float
                            self.training_metrics['best_checkpoint'] = int(step)

                        print(f"\n  📊 Step {step} | Val Loss: {val_loss_float:.4f} {'🎉 NEW BEST!' if is_best else ''}")

                    # Checkpointing
                    if step % save_every == 0 and step > 0:
                        is_best = (len(self.training_metrics['validation_losses']) > 0 and
                                 self.training_metrics['validation_losses'][-1] == self.training_metrics['best_val_loss'])
                        self.save_checkpoint(step, epoch, is_best=is_best)

                # Epoch summary
                epoch_time = time.time() - epoch_start
                avg_epoch_loss = np.mean(epoch_losses)
                avg_epoch_lr = np.mean(epoch_lrs)

                self.training_metrics['training_time'] += epoch_time

                print(f"\n✅ Epoch {epoch + 1} completed:")
                print(f"   Average Loss: {avg_epoch_loss:.4f}")
                print(f"   Average LR: {avg_epoch_lr:.2e}")
                print(f"   Time: {epoch_time/60:.1f} minutes")
                print(f"   Total time: {self.training_metrics['training_time']/3600:.1f} hours")

                # Checkpoint at end of epoch
                if (epoch + 1) % 5 == 0:  # Every 5 epochs
                    is_best = (len(self.training_metrics['validation_losses']) > 0 and
                             self.training_metrics['validation_losses'][-1] == self.training_metrics['best_val_loss'])
                    self.save_checkpoint(step, epoch + 1, is_best=is_best)

        except KeyboardInterrupt:
            print("\n⏹️  Training interrupted by user")
            print("💾 Saving emergency checkpoint...")
            self.save_checkpoint(step, epoch, is_best=False)

        # Final checkpoint
        total_time = time.time() - start_time
        print(f"\n🏁 Research Training Completed!")
        print(f"   Total time: {total_time/3600:.1f} hours")
        print(f"   Total steps: {step}")
        print(f"   Best validation loss: {self.training_metrics['best_val_loss']:.4f} at step {self.training_metrics['best_checkpoint']}")

        final_checkpoint = self.save_checkpoint(step, num_epochs, is_best=False)

        return self.training_metrics

def run_smoke_tested_experiment(config_name: str = 'xxlarge',
                               num_epochs: int = 50,
                               steps_per_epoch: int = 2000,
                               experiment_name: str = None,
                               run_smoke_test: bool = True):
    """
    Run a research experiment with comprehensive upfront smoke testing

    Args:
        config_name: Model configuration ('large', 'xlarge', 'xxlarge')
        num_epochs: Number of epochs (50-100 for research quality)
        steps_per_epoch: Steps per epoch (2000 recommended)
        experiment_name: Custom experiment name
        run_smoke_test: Whether to run smoke tests before training
    """

    if experiment_name is None:
        experiment_name = f"d3pm_tinystories_{config_name}_e{num_epochs}"

    print(f"🔬 SMOKE-TESTED D3PM EXPERIMENT")
    print(f"=" * 60)
    print(f"   Experiment: {experiment_name}")
    print(f"   Configuration: {config_name}")
    print(f"   Epochs: {num_epochs}")
    print(f"   Total steps: {num_epochs * steps_per_epoch:,}")
    print(f"   Smoke testing: {'✅ Enabled' if run_smoke_test else '❌ Disabled'}")

    # Get configuration
    configs = create_optimized_configs()
    config_dict = configs[config_name]
    config = D3PMConfig(**config_dict)

    total_steps = num_epochs * steps_per_epoch
    warmup_steps = min(5000, total_steps // 20)  # 5% warmup, max 5000 steps

    # Setup data
    try:
        if 'tokenizer' in globals() and 'train_dataset' in globals():
            print("♻️  Reusing existing tokenizer and datasets...")
            global tokenizer, train_dataset, val_dataset
        else:
            raise NameError("Need to setup data")
    except:
        print("🔧 Setting up tokenizer and datasets...")
        tokenizer = SentencePieceTokenizer(vocab_size=config.vocab_size)
        tokenizer.train_tokenizer(num_samples=50000)
        config.vocab_size = tokenizer.sp.vocab_size()

        train_dataset = RealTinyStoriesDataset(tokenizer, config.seq_length, "train")
        val_dataset = RealTinyStoriesDataset(tokenizer, config.seq_length, "validation")

    # Create smoke-testable trainer
    trainer = SmokeTestableResearchTrainer(
        config, tokenizer, train_dataset, val_dataset,
        warmup_steps=warmup_steps,
        warmup_type="linear",
        decay_type="cosine",
        use_gradient_clipping=True,
        experiment_name=experiment_name
    )

    # Run training with smoke testing
    metrics = trainer.research_training_loop(
        num_epochs=num_epochs,
        steps_per_epoch=steps_per_epoch,
        save_every=10000,
        eval_every=2000,
        eval_generation_every=20000,
        run_smoke_test=run_smoke_test
    )

    return trainer, metrics

print("""
🧪 COMPREHENSIVE SMOKE TESTING SYSTEM

Features:
✅ JSON serialization testing (all data types)
✅ File I/O testing (actual checkpoint writing)
✅ Mini training run (10 steps + validation + checkpoint)
✅ JAX/NumPy type conversion testing
✅ Full pipeline validation

Usage:
1. FULL SMOKE TEST (recommended):
   trainer, metrics = run_smoke_tested_experiment('xlarge', num_epochs=30)

2. SKIP SMOKE TEST (if you're confident):
   trainer, metrics = run_smoke_tested_experiment('xlarge', num_epochs=30, run_smoke_test=False)

3. SMOKE TEST ONLY (for debugging):
   trainer = SmokeTestableResearchTrainer(config, tokenizer, train_dataset, val_dataset)
   trainer.comprehensive_smoke_test()

The smoke test takes ~1-2 minutes but can save hours of wasted training!
""")

trainer, metrics = run_smoke_tested_experiment('xlarge', num_epochs=2)